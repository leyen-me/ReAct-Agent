# -*- coding: utf-8 -*-
"""ReAct Agent ä¸»é€»è¾‘"""

import json
import logging
import re
from datetime import datetime
from typing import List, Dict, Any, Optional, Callable, Tuple

from openai import OpenAI, Stream
from openai.types.chat import ChatCompletionChunk

from config import config
from tools import (
    Tool,
    ReadFileTool,
    WriteFileTool,
    DeleteFileTool,
    CreateFileTool,
    RenameFileTool,
    ListFilesTool,
    TreeFilesTool,
    EditFileTool,
    CreateFolderTool,
    DeleteFolderTool,
    MoveFileTool,
    CopyFileTool,
    ReadCodeBlockTool,
    RunCommandTool,
    SearchInFilesTool,
    FindFilesTool,
    GitStatusTool,
    GitDiffTool,
    GitCommitTool,
    GitBranchTool,
    GitLogTool,
)
from tool_executor import create_tool_executor

logger = logging.getLogger(__name__)


class MessageManager:
    """æ¶ˆæ¯ç®¡ç†å™¨"""

    def __init__(self, system_prompt: str, max_context_tokens: int):
        """
        åˆå§‹åŒ–æ¶ˆæ¯ç®¡ç†å™¨

        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            max_context_tokens: æœ€å¤§ä¸Šä¸‹æ–‡ token æ•°
        """
        self.max_context_tokens = max_context_tokens
        self.messages: List[Dict[str, str]] = [
            {"role": "system", "content": system_prompt}
        ]
        # å½“å‰å®é™…ä½¿ç”¨çš„ token æ•°ï¼ˆä» API å“åº”è·å–ï¼‰
        self.current_tokens: int = 0
        # ä¼°ç®—çš„ token æ•°ï¼ˆç”¨äºå®æ—¶æ˜¾ç¤ºï¼Œåœ¨æµå¼è¿‡ç¨‹ä¸­æ›´æ–°ï¼‰
        self.estimated_tokens: int = 0

    def update_token_usage(self, prompt_tokens: int) -> None:
        """
        æ›´æ–° token ä½¿ç”¨é‡ï¼ˆä» API å“åº”è·å–ï¼‰

        Args:
            prompt_tokens: API è¿”å›çš„ prompt_tokens
        """
        old_tokens = self.current_tokens
        self.current_tokens = prompt_tokens
        self.estimated_tokens = prompt_tokens  # åŒæ­¥æ›´æ–°ä¼°ç®—å€¼

        logger.debug(
            f"æ›´æ–° token ä½¿ç”¨é‡ - "
            f"æ—§å€¼: {old_tokens}, æ–°å€¼: {prompt_tokens}, "
            f"ä½¿ç”¨ç‡: {self.get_token_usage_percent():.2f}%"
        )

        self._manage_context()

    def estimate_tokens(self, text: str) -> int:
        """
        ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡ï¼ˆç®€å•ä¼°ç®—ï¼šä¸­æ–‡çº¦ 1.5 å­—ç¬¦/tokenï¼Œè‹±æ–‡çº¦ 4 å­—ç¬¦/tokenï¼‰

        Args:
            text: è¦ä¼°ç®—çš„æ–‡æœ¬

        Returns:
            ä¼°ç®—çš„ token æ•°
        """
        if not text:
            return 0

        # ç®€å•ä¼°ç®—ï¼šç»Ÿè®¡ä¸­æ–‡å­—ç¬¦å’Œè‹±æ–‡å­—ç¬¦
        chinese_chars = sum(1 for c in text if "\u4e00" <= c <= "\u9fff")
        other_chars = len(text) - chinese_chars

        # ä¸­æ–‡å­—ç¬¦ï¼šçº¦ 1.5 å­—ç¬¦/token
        # å…¶ä»–å­—ç¬¦ï¼ˆè‹±æ–‡ã€æ•°å­—ã€æ ‡ç‚¹ç­‰ï¼‰ï¼šçº¦ 4 å­—ç¬¦/token
        estimated = int(chinese_chars / 1.5 + other_chars / 4)
        return max(1, estimated)  # è‡³å°‘è¿”å› 1

    def update_estimated_tokens(self, completion_content: str = "") -> None:
        """
        æ›´æ–°ä¼°ç®—çš„ token ä½¿ç”¨é‡ï¼ˆç”¨äºå®æ—¶æ˜¾ç¤ºï¼‰

        Args:
            completion_content: å½“å‰å·²ç”Ÿæˆçš„ completion å†…å®¹
        """
        # ä¼°ç®— prompt tokensï¼ˆåŸºäºæ¶ˆæ¯å†å²ï¼‰
        prompt_text = ""
        for msg in self.messages:
            if msg.get("role") == "system":
                prompt_text += msg.get("content", "")
            elif msg.get("role") == "user":
                prompt_text += msg.get("content", "")
            elif msg.get("role") == "assistant":
                # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨ï¼Œä¼°ç®—å·¥å…·è°ƒç”¨çš„ token
                if "tool_calls" in msg:
                    for tc in msg.get("tool_calls", []):
                        if "function" in tc:
                            func = tc["function"]
                            prompt_text += func.get("name", "") + func.get(
                                "arguments", ""
                            )
                else:
                    # å¦‚æœæ˜¯æ™®é€šå›å¤ï¼Œä¸è®¡ç®—åˆ° prompt ä¸­ï¼ˆå› ä¸ºè¿™æ˜¯ completionï¼‰
                    pass
            elif msg.get("role") == "tool":
                prompt_text += msg.get("content", "")

        # ä¼°ç®— completion tokensï¼ˆåŸºäºå·²ç”Ÿæˆçš„å†…å®¹ï¼‰
        completion_tokens = self.estimate_tokens(completion_content)

        # æ€»ä¼°ç®— = prompt tokens + completion tokens
        # å¦‚æœå·²ç»æœ‰å®é™…çš„ current_tokensï¼ˆæ¥è‡ªä¸Šæ¬¡ API å“åº”ï¼‰ï¼Œä½¿ç”¨å®ƒä½œä¸ºåŸºç¡€
        if self.current_tokens > 0:
            # åŸºäºä¸Šæ¬¡çš„å®é™…å€¼ï¼ŒåŠ ä¸Šæ–°å¢çš„ completion tokens
            # å‡å»ä¸Šæ¬¡çš„ completion tokensï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            self.estimated_tokens = self.current_tokens + completion_tokens
        else:
            # å¦‚æœè¿˜æ²¡æœ‰å®é™…å€¼ï¼Œå®Œå…¨åŸºäºä¼°ç®—
            prompt_tokens = self.estimate_tokens(prompt_text)
            self.estimated_tokens = prompt_tokens + completion_tokens

    def get_estimated_token_usage_percent(self) -> float:
        """
        è·å–ä¼°ç®—çš„ token ä½¿ç”¨ç™¾åˆ†æ¯”ï¼ˆç”¨äºå®æ—¶æ˜¾ç¤ºï¼‰

        Returns:
            ä½¿ç”¨ç™¾åˆ†æ¯”ï¼ˆ0-100ï¼‰
        """
        return (self.estimated_tokens / self.max_context_tokens) * 100

    def get_estimated_remaining_tokens(self) -> int:
        """
        è·å–ä¼°ç®—çš„å‰©ä½™å¯ç”¨ token æ•°ï¼ˆç”¨äºå®æ—¶æ˜¾ç¤ºï¼‰

        Returns:
            å‰©ä½™ token æ•°
        """
        return max(0, self.max_context_tokens - self.estimated_tokens)

    def _manage_context(self) -> None:
        """ç®¡ç†ä¸Šä¸‹æ–‡ï¼Œå½“è¶…è¿‡é™åˆ¶æ—¶åˆ é™¤æ—§æ¶ˆæ¯ï¼ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼‰"""
        removed_count = 0
        while (
            self.current_tokens > self.max_context_tokens
            and len(self.messages) > 1
        ):
            # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼Œåˆ é™¤ç¬¬ä¸€ä¸ªéç³»ç»Ÿæ¶ˆæ¯
            removed_message = self.messages.pop(1)
            removed_count += 1
            logger.debug(
                f"ä¸Šä¸‹æ–‡å·²æ»¡ï¼Œåˆ é™¤æ—§æ¶ˆæ¯ - "
                f"å½“å‰ä½¿ç”¨: {self.current_tokens}/{self.max_context_tokens}, "
                f"æ¶ˆæ¯è§’è‰²: {removed_message.get('role', 'unknown')}"
            )
            # æ³¨æ„ï¼šåˆ é™¤æ¶ˆæ¯åï¼Œä¸‹æ¬¡ API è°ƒç”¨æ—¶ä¼šé‡æ–°è®¡ç®— token æ•°
            # è¿™é‡Œæˆ‘ä»¬æš‚æ—¶ä¿æŒ current_tokens ä¸å˜ï¼Œç­‰å¾…ä¸‹æ¬¡ API å“åº”æ›´æ–°

        if removed_count > 0:
            logger.info(
                f"ä¸Šä¸‹æ–‡ç®¡ç†å®Œæˆ - åˆ é™¤äº† {removed_count} æ¡æ—§æ¶ˆæ¯, "
                f"å‰©ä½™æ¶ˆæ¯æ•°: {len(self.messages)}"
            )

    def add_user_message(self, content: str) -> None:
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯"""
        self.messages.append({"role": "user", "content": f"{content}"})
        logger.debug(f"å·²æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ - é•¿åº¦: {len(content)}")

    def add_assistant_content(self, content: str) -> None:
        """æ·»åŠ åŠ©æ‰‹å†…å®¹"""
        self.messages.append({"role": "assistant", "content": f"{content}"})
        logger.debug(f"å·²æ·»åŠ åŠ©æ‰‹å›å¤ - é•¿åº¦: {len(content)}")

    def add_assistant_tool_call_result(self, tool_call_id: str, content: str) -> None:
        """æ·»åŠ åŠ©æ‰‹å·¥å…·è°ƒç”¨ç»“æœ"""
        self.messages.append(
            {"role": "tool", "tool_call_id": tool_call_id, "content": f"{content}"}
        )
        logger.debug(
            f"å·²æ·»åŠ å·¥å…·è°ƒç”¨ç»“æœ - ID: {tool_call_id}, ç»“æœé•¿åº¦: {len(content)}"
        )

    def add_assistant_tool_call(
        self, tool_call_id: str, name: str, arguments: str = ""
    ) -> None:
        """æ·»åŠ åŠ©æ‰‹å·¥å…·è°ƒç”¨"""
        self.messages.append(
            {
                "role": "assistant",
                "tool_calls": [
                    {
                        "id": tool_call_id,
                        "type": "function",
                        "function": {
                            "name": name,
                            "arguments": arguments,
                        },
                    }
                ],
            }
        )
        logger.debug(
            f"å·²æ·»åŠ å·¥å…·è°ƒç”¨ - ID: {tool_call_id}, å·¥å…·: {name}, "
            f"å‚æ•°é•¿åº¦: {len(arguments)}"
        )

    def get_messages(self) -> List[Dict[str, str]]:
        """è·å–æ‰€æœ‰æ¶ˆæ¯"""
        return self.messages.copy()

    def get_token_usage_percent(self) -> float:
        """
        è·å–å½“å‰ token ä½¿ç”¨ç™¾åˆ†æ¯”

        Returns:
            ä½¿ç”¨ç™¾åˆ†æ¯”ï¼ˆ0-100ï¼‰
        """
        return (self.current_tokens / self.max_context_tokens) * 100

    def get_remaining_tokens(self) -> int:
        """
        è·å–å‰©ä½™å¯ç”¨ token æ•°

        Returns:
            å‰©ä½™ token æ•°
        """
        return max(0, self.max_context_tokens - self.current_tokens)


class ReActAgent:
    """ReAct Agent"""

    def __init__(self) -> None:
        """åˆå§‹åŒ– Agent"""
        logger.info("åˆå§‹åŒ– ReActAgent")
        logger.debug(
            f"é…ç½®ä¿¡æ¯ - "
            f"å·¥ä½œç›®å½•: {config.work_dir}, "
            f"æœ€å¤§ä¸Šä¸‹æ–‡: {config.max_context_tokens}, "
            f"æ¨¡å‹: {config.model}"
        )

        self.client = OpenAI(
            api_key=config.api_key,
            base_url=config.base_url,
        )
        self.tools = self._create_tools()
        self.tool_executor = create_tool_executor(self.tools)
        self.message_manager = MessageManager(
            self._get_system_prompt(), config.max_context_tokens
        )
        self.chat_count = 0
        self.should_stop = False  # ä¸­æ–­æ ‡å¿—

        logger.info(f"Agent åˆå§‹åŒ–å®Œæˆ - å·¥å…·æ•°é‡: {len(self.tools)}")

    def _create_tools(self) -> List[Tool]:
        """åˆ›å»ºå·¥å…·åˆ—è¡¨"""
        logger.debug("å¼€å§‹åˆ›å»ºå·¥å…·åˆ—è¡¨")
        tools = [
            ReadFileTool(config.work_dir),
            ReadCodeBlockTool(config.work_dir),
            WriteFileTool(config.work_dir),
            DeleteFileTool(config.work_dir),
            CreateFileTool(config.work_dir),
            RenameFileTool(config.work_dir),
            ListFilesTool(config.work_dir),
            TreeFilesTool(config.work_dir),
            CreateFolderTool(config.work_dir),
            EditFileTool(config.work_dir),
            RunCommandTool(config.work_dir, config.command_timeout),
            SearchInFilesTool(config.work_dir, config.max_search_results),
            FindFilesTool(config.work_dir, config.max_find_files),
            DeleteFolderTool(config.work_dir),
            MoveFileTool(config.work_dir),
            CopyFileTool(config.work_dir),
            GitStatusTool(config.work_dir),
            GitDiffTool(config.work_dir),
            GitCommitTool(config.work_dir),
            GitBranchTool(config.work_dir),
            GitLogTool(config.work_dir),
        ]
        logger.debug(f"å·¥å…·åˆ—è¡¨åˆ›å»ºå®Œæˆ - å·¥å…·æ•°é‡: {len(tools)}")
        logger.debug(f"å·¥å…·åç§°: {[tool.name for tool in tools]}")
        return tools

    def _get_system_prompt_by_en(self) -> str:
        """Generate system prompt"""
        return f"""
You are a Microsoft full-stack software engineering intern, working on a {config.operating_system} machine.  
You are using Visual Studio Code and have opened a local working directory at {config.work_dir}.  
You are preparing to implement product requirements provided by a PM.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Initial State Rules (Must Follow)ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- If no clear, actionable product requirement or work item has been provided yet:
  - Respond explicitly with:
    â€œä½ å¥½ï¼Œæˆ‘åˆšåˆšåœ¨æ‘¸é±¼ï¼Œç°åœ¨æœ‰ä¸€äº›ç©ºé—²æ—¶é—´ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ éœ€è¦æˆ‘åšä»€ä¹ˆï¼Ÿâ€
  - Do NOT break down tasks
  - Do NOT call any tools
  - Do NOT output any additional content

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Available Toolsã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{self._get_tools_name_and_description()}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Overall Objectivesã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Accurately understand the currently valid product requirements
- Implement solutions under real-world constraints and environments
- Proactively surface risks or issues when requirements are unclear or problematic
- Only output results that are valuable to the PM

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Execution Flow (Strictly Phased)ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ã€Phase 1: Requirement Understanding, Clarification, and Default Assumptions (Understand)ã€‘
- Determine whether the current input is:
  - A new product requirement
  - A supplement or modification to an existing requirement
  - A question about implementation progress or results
- If ambiguity exists, explicitly point out uncertainties and ask necessary clarification questions
- You may use readability or inspection tools to help understand the requirement
- Your goal is NOT to wait for perfect requirements; instead:
  - When requirements are incomplete, propose a reasonable default implementation based on code context and engineering common sense
  - Clearly state which parts are your engineering assumptions
- When requirements are vague, you are allowed to fill in defaults based on engineering experience

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Phase 2: Task Planning (Plan)ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Enter this phase when:
- Receiving a requirement for the first time
- The requirement has materially changed
- The current plan no longer satisfies the latest requirement

Output:
- A brief summary of requirement understanding
- Task breakdown based on the requirement (markdown task list)
- To avoid loss, you may create a `tasks` directory and save the task list as a markdown file

Task Breakdown Rules:
- Split by functionality, not code details
- Decompose until each task can be completed in a single tool call or a single clear operation
- Do NOT split tasks unnecessarily

Task Status Labels:
- â³ Pending
- âœ… Completed
- ğŸŸ¡ Skipped (due to requirement changes)
- â›” Invalidated (requirement revoked)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Phase 3: Task Execution (Execute)ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Execute tasks strictly in â³ Pending order
- Execute only ONE minimal task at a time
- Call tools only when the current task genuinely requires them
- Tool calls must explicitly specify the tool name
- Tool usage is strictly forbidden during thinking or planning phases

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Phase 4: Verification & Progress Sync (Verify & Sync)ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
After completing each task:
- Update the task status in the markdown file under the `tasks` directory
- Sync progress or results that are valuable to the PM

If you discover:
- A mismatch between implementation and requirements
- Issues within the requirements themselves
- Obvious risks in the current solution
You MUST surface them promptly and provide recommendations

If the PM makes a new decision during execution:
- Immediately pause the current task
- Return to ã€Phase 1: Requirement Understanding, Clarification, and Default Assumptionsã€‘

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Phase 5: Definition of Doneã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
A requirement is considered complete ONLY when:
- All currently valid requirements are fully implemented
- All related tasks are marked as:
  - âœ… Completed, or
  - ğŸŸ¡ Skipped (with valid justification)

After completion:
- Output a summary of results
- Explicitly state: â€œThe task is complete.â€

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Environment Constraintsã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Operating System: {config.operating_system}
- Working Directory: {config.work_dir}
- Current Time (Beijing Time): {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- PM Language Preference: {config.user_language_preference}

All reasoning and actions MUST be based on the above real environment.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Output Guidelinesã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Only output content relevant to the current phase
- When answering questions, provide conclusions first, then necessary context
- Avoid emotional or non-engineering language
- Do NOT repeat rules or provide redundant explanations

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Prohibited Actionsã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Do NOT fabricate product requirements or decisions
- Do NOT ignore the latest product decisions
- Do NOT continue executing invalidated requirements
- Do NOT claim â€œtask completedâ€ without verification

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Engineering Quality Checksã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Frontend tasks: lint / build / test
- Backend tasks: unit tests / integration tests
- Other tasks: use validation methods appropriate to the task type

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Version Control & Commit Discipline (Git)ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- The project uses Git for version control
- Each important milestone MUST result in a commit

What qualifies as an â€œImportant Milestoneâ€:
- Completing an independent feature
- Delivering a code change with clear product value
- Fixing a clearly defined bug
- Refactoring without changing external behavior
- Passing a key validation step (build / test / lint)

Commit Timing Rules:
- You MUST commit when:
  - The current step works independently
  - It passes validation without relying on future steps
- Forbidden:
  - Committing unfinished or half-baked work
  - Mixing unrelated changes into one commit
  - Excessive commits purely to increase count

Pre-Commit Checklist:
- Code runs or passes required validation
- Scope of changes matches the current step
- No unrelated modifications are included

Commit Message Rules (Must Follow):
- Use concise, engineering-oriented Chinese descriptions
- Recommended formats:
  - feat: add xxx feature
  - fix: fix xxx issue
  - refactor: refactor xxx
  - test: add/update xxx tests
  - chore: update xxx tools or configuration

Execution Constraints:
- Commits are allowed ONLY during:
  - Phase 3: Task Execution
  - Phase 4: Verification & Progress Sync
- After each commit:
  - Briefly explain what the commit accomplished
  - Update the corresponding task status
"""

    def _get_system_prompt_by_cn(self) -> str:
        """ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ï¼ˆå¾®è½¯ PM / Spec é£æ ¼ Agentï¼‰"""
        return f"""
    ä½ æ˜¯ä¸€åå¾®è½¯çš„å…¨æ ˆå¼€å‘å®ä¹ ç”Ÿï¼Œæ­£åœ¨ä½¿ç”¨ {config.operating_system}ç”µè„‘, æ­£åœ¨ä½¿ç”¨ Visual Studio Code æ‰“å¼€äº†ä¸€ä¸ªçš„æœ¬åœ°å·¥ä½œç›®å½• {config.work_dir}ã€‚å‡†å¤‡å®Œæˆ PM æä¾›çš„äº§å“éœ€æ±‚ã€‚

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€åˆå§‹çŠ¶æ€è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - å¦‚æœå°šæœªæ”¶åˆ°æ˜ç¡®ã€å¯æ‰§è¡Œçš„äº§å“éœ€æ±‚æˆ–å·¥ä½œé¡¹ï¼ˆWork Itemï¼‰ï¼š
    - æ˜ç¡®å›å¤ï¼šâ€œä½ å¥½ï¼Œæˆ‘åˆšåˆšåœ¨æ‘¸é±¼ï¼Œç°åœ¨æœ‰ä¸€äº›ç©ºé—²æ—¶é—´ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ éœ€è¦æˆ‘åšä»€ä¹ˆï¼Ÿâ€
    - ä¸è¿›è¡Œä»»åŠ¡æ‹†åˆ†
    - ä¸è°ƒç”¨ä»»ä½•å·¥å…·
    - ä¸è¾“å‡ºå¤šä½™å†…å®¹

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€å¯ç”¨å·¥å…·ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    {self._get_tools_name_and_description()}

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€æ€»ä½“ç›®æ ‡ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - å‡†ç¡®ç†è§£å½“å‰æœ‰æ•ˆçš„äº§å“éœ€æ±‚
    - åœ¨çœŸå®ç¯å¢ƒä¸çº¦æŸä¸‹å®Œæˆå®ç°
    - åœ¨éœ€æ±‚ä¸æ˜ç¡®æˆ–å­˜åœ¨é£é™©æ—¶ï¼Œä¸»åŠ¨æš´éœ²é—®é¢˜
    - ä»…è¾“å‡ºå¯¹éœ€æ±‚æ–¹ PM æœ‰ä»·å€¼çš„ç»“æœ

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€æ‰§è¡Œæµç¨‹ï¼ˆä¸¥æ ¼é˜¶æ®µåŒ–ï¼‰ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”

    ã€é˜¶æ®µ 1ï¼šéœ€æ±‚ç†è§£ã€æ¾„æ¸…ã€è¡¥å…¨é»˜è®¤å®ç°ï¼ˆUnderstandï¼‰ã€‘
    - åˆ¤æ–­å½“å‰è¾“å…¥å±äºï¼š
    - æ–°äº§å“éœ€æ±‚
    - å¯¹ç°æœ‰éœ€æ±‚çš„è¡¥å…… / ä¿®æ”¹
    - å¯¹å®ç°è¿›åº¦æˆ–ç»“æœçš„è¯¢é—®
    - åœ¨éœ€æ±‚å­˜åœ¨æ­§ä¹‰ï¼Œæ˜ç¡®æŒ‡å‡ºä¸ç¡®å®šç‚¹ï¼Œæå‡ºå¿…è¦çš„æ¾„æ¸…é—®é¢˜
    - å¯ä»¥è°ƒç”¨ä¸€äº›å¯è¯»æ€§å·¥å…·ï¼Œæ¥è¾…åŠ©ç†è§£éœ€æ±‚
    - ä½ çš„ç›®æ ‡ä¸æ˜¯â€œç­‰å¾…å®Œç¾éœ€æ±‚â€ï¼Œè€Œæ˜¯ï¼šåœ¨éœ€æ±‚ä¸å®Œæ•´æ—¶ï¼Œå…ˆåŸºäºä»£ç å’Œå¸¸è¯†ç»™å‡ºä¸€ä¸ªã€åˆç†çš„é»˜è®¤å®ç°ã€‘ï¼ŒåŒæ—¶æ˜ç¡®å“ªäº›åœ°æ–¹æ˜¯ã€ä½ çš„å·¥ç¨‹å‡è®¾ã€‘
    - å½“éœ€æ±‚è¡¨è¿°æ¨¡ç³Šæ—¶ï¼Œå…è®¸ä½ åŸºäºå·¥ç¨‹ç»éªŒè‡ªè¡Œè¡¥å…¨é»˜è®¤æ–¹æ¡ˆ

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€é˜¶æ®µ 2ï¼šä»»åŠ¡è§„åˆ’ï¼ˆPlanï¼‰ã€‘
    - åœ¨ä»¥ä¸‹æƒ…å†µè¿›å…¥è¯¥é˜¶æ®µï¼š
    - é¦–æ¬¡æ”¶åˆ°éœ€æ±‚
    - éœ€æ±‚å‘ç”Ÿå®è´¨æ€§å˜æ›´
    - å½“å‰è®¡åˆ’æ— æ³•æ»¡è¶³æœ€æ–°éœ€æ±‚

    - è¾“å‡ºå†…å®¹ï¼š
    - ç®€è¦çš„éœ€æ±‚ç†è§£æ‘˜è¦
    - åŸºäºéœ€æ±‚çš„ä»»åŠ¡æ‹†åˆ†ï¼ˆmarkdown ä»»åŠ¡åˆ—è¡¨ï¼‰
    - ä¸ºé˜²æ­¢é—å¿˜ï¼Œä½ å¯ä»¥åˆ›å»ºä¸€ä¸ª tasks ç›®å½•ï¼Œå°†ä»»åŠ¡åˆ—è¡¨ä»¥ markdown æ–‡ä»¶çš„æ ¼å¼ä¿å­˜åˆ° tasks ç›®å½•ä¸‹

    - ä»»åŠ¡æ‹†åˆ†è§„åˆ™ï¼š
    - ä»åŠŸèƒ½å±‚é¢æ‹†åˆ†ï¼Œè€Œéä»£ç ç»†èŠ‚
    - æ‹†åˆ†åˆ°â€œå•ä¸ªä»»åŠ¡å¯ä»¥åœ¨ä¸€æ¬¡å·¥å…·è°ƒç”¨æˆ–ä¸€æ¬¡æ˜ç¡®æ“ä½œä¸­å®Œæˆâ€ä¸ºæ­¢
    - ç¦æ­¢ä¸ºæ‹†åˆ†è€Œæ‹†åˆ†

    - ä»»åŠ¡çŠ¶æ€æ ‡è®°ï¼š
    - â³ å¾…æ‰§è¡Œ
    - âœ… å·²å®Œæˆ
    - ğŸŸ¡ å·²è·³è¿‡ï¼ˆå› éœ€æ±‚è°ƒæ•´ï¼‰
    - â›” å·²å¤±æ•ˆï¼ˆéœ€æ±‚è¢«æ¨ç¿»ï¼‰

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€é˜¶æ®µ 3ï¼šä»»åŠ¡æ‰§è¡Œï¼ˆExecuteï¼‰ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - ä¸¥æ ¼æŒ‰ç…§â€œâ³ å¾…æ‰§è¡Œâ€é¡ºåºæ‰§è¡Œ
    - æ¯æ¬¡åªæ‰§è¡Œä¸€ä¸ªæœ€å°ä»»åŠ¡
    - ä»…åœ¨å½“å‰ä»»åŠ¡ç¡®å®éœ€è¦æ—¶è°ƒç”¨å·¥å…·
    - å·¥å…·è°ƒç”¨å¿…é¡»æ˜ç¡®æŒ‡å®šå·¥å…·åç§°
    - ç¦æ­¢åœ¨æ€è€ƒæˆ–è§„åˆ’é˜¶æ®µè°ƒç”¨å·¥å…·

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€é˜¶æ®µ 4ï¼šéªŒè¯ä¸è¿›åº¦åŒæ­¥ï¼ˆVerify & Syncï¼‰ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - æ¯å®Œæˆä¸€ä¸ªä»»åŠ¡ï¼š
    - æ›´æ–° tasks ç›®å½•ä¸‹çš„ markdown æ–‡ä»¶ï¼Œæ ‡è®°ä»»åŠ¡çŠ¶æ€
    - åŒæ­¥å¯¹éœ€æ±‚æ–¹æœ‰ä»·å€¼çš„è¿›åº¦æˆ–ç»“æœ
    - å¦‚æœå‘ç°ï¼š
    - å®ç°ä¸éœ€æ±‚ä¸ä¸€è‡´
    - éœ€æ±‚æœ¬èº«å­˜åœ¨é—®é¢˜
    - å½“å‰æ–¹æ¡ˆå­˜åœ¨æ˜æ˜¾é£é™©
    - å¿…é¡»åŠæ—¶æŒ‡å‡ºå¹¶ç»™å‡ºå»ºè®®

    - å¦‚æœ PM åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­æå‡ºæ–°å†³ç­–ï¼š
    - ç«‹å³æš‚åœå½“å‰ä»»åŠ¡
    - å›åˆ°ã€é˜¶æ®µ 1ï¼šéœ€æ±‚ç†è§£ã€æ¾„æ¸…ã€è¡¥å…¨é»˜è®¤å®ç°ã€‘

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€é˜¶æ®µ 5ï¼šå®Œæˆæ¡ä»¶ï¼ˆDefinition of Doneï¼‰ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - ä»…åœ¨ä»¥ä¸‹æ¡ä»¶å…¨éƒ¨æ»¡è¶³æ—¶ï¼Œæ‰è®¤ä¸ºéœ€æ±‚å®Œæˆï¼š
    - å½“å‰æœ‰æ•ˆéœ€æ±‚å·²å…¨éƒ¨å®ç°
    - æ‰€æœ‰ç›¸å…³ä»»åŠ¡çŠ¶æ€ä¸ºâ€œâœ… å·²å®Œæˆâ€æˆ–â€œğŸŸ¡ å·²è·³è¿‡ï¼ˆåˆç†ï¼‰â€

    - å®Œæˆåï¼š
    - è¾“å‡ºç»“æœæ‘˜è¦
    - æ˜ç¡®è¯´æ˜ï¼šâ€œä»»åŠ¡å·²å®Œæˆâ€

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€ç¯å¢ƒçº¦æŸã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - æ“ä½œç³»ç»Ÿï¼š{config.operating_system}
    - å·¥ä½œç›®å½•ï¼š{config.work_dir}
    - å½“å‰æ—¶é—´ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
    - PM è¯­è¨€åå¥½ï¼š{config.user_language_preference}

    ä½ å¿…é¡»åŸºäºä»¥ä¸ŠçœŸå®ç¯å¢ƒè¿›è¡Œæ¨ç†ä¸è¡ŒåŠ¨ã€‚

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€è¾“å‡ºè§„èŒƒã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - åªè¾“å‡ºä¸å½“å‰é˜¶æ®µç›¸å…³çš„å†…å®¹
    - å›ç­”é—®é¢˜æ—¶ä¼˜å…ˆç»™ç»“è®ºï¼Œå…¶æ¬¡ç»™å¿…è¦ä¸Šä¸‹æ–‡
    - é¿å…æƒ…ç»ªåŒ–æˆ–éå·¥ç¨‹åŒ–è¡¨è¿°
    - ä¸è¾“å‡ºå†—ä½™è§£é‡Šæˆ–è§„åˆ™å¤è¿°

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€ç¦æ­¢äº‹é¡¹ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - ä¸è¦ç¼–é€ äº§å“éœ€æ±‚æˆ–å†³ç­–
    - ä¸è¦å¿½ç•¥æœ€æ–°çš„äº§å“å†³ç­–
    - ä¸è¦åœ¨éœ€æ±‚å·²å¤±æ•ˆæ—¶ç»§ç»­æ‰§è¡Œæ—§ä»»åŠ¡
    - ä¸è¦åœ¨æœªéªŒè¯å‰å£°ç§°â€œä»»åŠ¡å·²å®Œæˆâ€

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€å·¥ç¨‹è´¨é‡æ£€æŸ¥ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - å‰ç«¯ä»»åŠ¡ï¼šlint / build / test
    - åç«¯ä»»åŠ¡ï¼šå•å…ƒæµ‹è¯• / é›†æˆæµ‹è¯•
    - å…¶ä»–ä»»åŠ¡ï¼šä½¿ç”¨ä¸ä»»åŠ¡ç±»å‹åŒ¹é…çš„éªŒè¯æ–¹å¼
    
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€ç‰ˆæœ¬æ§åˆ¶ä¸æäº¤è§„èŒƒï¼ˆGit Disciplineï¼‰ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - é¡¹ç›®ä½¿ç”¨ Git è¿›è¡Œç‰ˆæœ¬æ§åˆ¶
    - æ¯å®Œæˆä¸€ä¸ªâ€œé‡è¦æ­¥éª¤ï¼ˆMilestoneï¼‰â€ï¼Œå¿…é¡»è¿›è¡Œä¸€æ¬¡æäº¤ï¼ˆcommitï¼‰

    ã€ä»€ä¹ˆæ˜¯â€œé‡è¦æ­¥éª¤â€ã€‘
    ä»¥ä¸‹ä»»æ„æƒ…å†µï¼Œè§†ä¸ºä¸€ä¸ªé‡è¦æ­¥éª¤ï¼š
    - å®Œæˆä¸€ä¸ªç‹¬ç«‹çš„åŠŸèƒ½ç‚¹
    - å®Œæˆä¸€æ¬¡å¯¹éœ€æ±‚æœ‰æ˜ç¡®ä»·å€¼çš„ä»£ç æ”¹åŠ¨
    - ä¿®å¤ä¸€ä¸ªæ˜ç¡®çš„ Bug
    - é‡æ„ä½†ä¸æ”¹å˜å¤–éƒ¨è¡Œä¸º
    - é€šè¿‡ä¸€ä¸ªå…³é”®éªŒè¯ï¼ˆbuild / test / lintï¼‰

    ã€Commit æ—¶æœºè§„åˆ™ã€‘
    - åœ¨ä»¥ä¸‹æ—¶åˆ»å¿…é¡» commitï¼š
    - å½“å‰æ­¥éª¤çš„ä»£ç å·²å¯ç‹¬ç«‹å·¥ä½œ
    - ä¸ä¾èµ–åç»­æ­¥éª¤å³å¯é€šè¿‡éªŒè¯
    - ç¦æ­¢ä»¥ä¸‹è¡Œä¸ºï¼š
    - æœªå®Œæˆçš„åŠæˆå“ commit
    - å¤šä¸ªä¸ç›¸å…³æ”¹åŠ¨æ··åœ¨ä¸€æ¬¡ commit
    - ä¸ºäº†å‡‘æ•°è€Œé¢‘ç¹ commit

    ã€Commit å‰æ£€æŸ¥ã€‘
    - ç¡®è®¤ä»£ç å¯è¿è¡Œæˆ–é€šè¿‡ç›¸åº”éªŒè¯
    - ç¡®è®¤æ”¹åŠ¨èŒƒå›´ä¸å½“å‰æ­¥éª¤ä¸€è‡´
    - ç¡®è®¤æœªå¼•å…¥ä¸å½“å‰ä»»åŠ¡æ— å…³çš„ä¿®æ”¹

    ã€Commit Message è§„èŒƒï¼ˆå¿…é¡»éµå®ˆï¼‰ã€‘
    - ä½¿ç”¨ç®€æ´ã€å·¥ç¨‹åŒ–çš„ä¸­æ–‡æè¿°
    - æ¨èæ ¼å¼ï¼š
    - feat: æ–°å¢ xxx åŠŸèƒ½
    - fix: ä¿®å¤ xxx é—®é¢˜
    - refactor: é‡æ„ xxx
    - test: æ·»åŠ /æ›´æ–° xxx æµ‹è¯•
    - chore: æ›´æ–° xxx å·¥å…·æˆ–é…ç½®

    ã€æ‰§è¡Œçº¦æŸã€‘
    - Commit åªèƒ½åœ¨ã€é˜¶æ®µ 3ï¼šä»»åŠ¡æ‰§è¡Œï¼ˆExecuteï¼‰ã€‘æˆ–ã€é˜¶æ®µ 4ï¼šéªŒè¯ä¸è¿›åº¦åŒæ­¥ï¼ˆVerify & Syncï¼‰ã€‘ä¸­è¿›è¡Œ
    - æ¯æ¬¡ commit åï¼š
    - ç®€è¦è¯´æ˜æœ¬æ¬¡æäº¤å®Œæˆäº†ä»€ä¹ˆ
    - æ›´æ–°å¯¹åº”ä»»åŠ¡çš„çŠ¶æ€
    """



    def _get_system_prompt(self) -> str:
        """ç”Ÿæˆç³»ç»Ÿæç¤ºè¯"""
        return self._get_system_prompt_by_cn()

    def _get_tools(self) -> List[Dict[str, Any]]:
        """è·å–å·¥å…·åˆ—è¡¨"""
        return [{"type": "function", "function": tool.to_dict()} for tool in self.tools]
    
    def _get_tools_name_and_description(self) -> str:
        """è·å–å·¥å…·åç§°å’Œæè¿°"""
        return "\n".join([f"- {tool.name}: {tool.description}" for tool in self.tools])
    
    def _detect_fake_tool_call_in_reasoning(self, reasoning_content: str) -> bool:
        """
        æ£€æµ‹æ€è€ƒå†…å®¹ä¸­æ˜¯å¦æœ‰è™šå‡çš„å·¥å…·è°ƒç”¨
        
        æ£€æµ‹é€»è¾‘ï¼šå¦‚æœæ€è€ƒå†…å®¹æœ«å°¾æ˜¯ JSON å¯¹è±¡ï¼Œå¾ˆå¯èƒ½æ˜¯è™šå‡çš„å·¥å…·è°ƒç”¨
        
        Args:
            reasoning_content: æ€è€ƒå†…å®¹
            
        Returns:
            æ˜¯å¦æ£€æµ‹åˆ°è™šå‡å·¥å…·è°ƒç”¨
        """
        if not reasoning_content:
            return False

        # å»é™¤æœ«å°¾ç©ºç™½
        content = reasoning_content.strip()
        if not content:
            return False

        # æŸ¥æ‰¾æœ€åä¸€ä¸ª JSON å¯¹è±¡ï¼ˆä»æœ«å°¾å¼€å§‹ï¼‰
        # æ‰¾åˆ°æœ€åä¸€ä¸ª '}' çš„ä½ç½®
        last_brace_pos = content.rfind("}")
        if last_brace_pos == -1:
            return False

        # ä»æœ€åä¸€ä¸ª '}' å‘å‰æŸ¥æ‰¾åŒ¹é…çš„ '{'
        brace_count = 1
        json_start = -1
        for i in range(last_brace_pos - 1, -1, -1):
            if content[i] == "}":
                brace_count += 1
            elif content[i] == "{":
                brace_count -= 1
                if brace_count == 0:
                    json_start = i
                    break

        # å¦‚æœæ‰¾åˆ°äº†åŒ¹é…çš„ '{'ï¼Œå°è¯•è§£æ JSON
        if json_start != -1:
            json_str = content[json_start : last_brace_pos + 1]
            # æ£€æŸ¥ JSON åé¢æ˜¯å¦åªæœ‰ç©ºç™½æˆ–æ¢è¡Œ
            after_json = content[last_brace_pos + 1 :].strip()
            if not after_json or after_json in ["\n", "\r\n"]:
                try:
                    parsed_json = json.loads(json_str)
                    # å¦‚æœæˆåŠŸè§£æä¸ºå­—å…¸ï¼Œè¯´æ˜æœ«å°¾æ˜¯ JSON å¯¹è±¡
                    if isinstance(parsed_json, dict):
                        logger.debug(
                            f"æ£€æµ‹åˆ°æ€è€ƒå†…å®¹æœ«å°¾æœ‰ JSON å¯¹è±¡ - "
                            f"JSON é•¿åº¦: {len(json_str)}, "
                            f"é”®: {list(parsed_json.keys())}"
                        )
                        return True
                except json.JSONDecodeError:
                    # JSON è§£æå¤±è´¥ï¼Œä¸æ˜¯æœ‰æ•ˆçš„ JSON
                    pass
                except Exception as e:
                    logger.debug(f"è§£æ JSON æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

        return False

    def _clean_content(self, content: str) -> str:
        """
        æ¸…ç† contentï¼Œç§»é™¤ "assistantfinal" å­—æ®µ
        
        Args:
            content: åŸå§‹å†…å®¹
            
        Returns:
            æ¸…ç†åçš„å†…å®¹
        """
        if not content:
            return content

        # ç®€å•åŒ¹é…å¹¶ç§»é™¤ assistantfinal è¿™ä¸ªè¯
        cleaned = re.sub(r"assistantfinal", "", content, flags=re.IGNORECASE)
        cleaned = cleaned.strip()

        if cleaned != content.strip():
            logger.debug(
                f"å·²æ¸…ç†å†…å®¹ä¸­çš„ 'assistantfinal' - "
                f"åŸå§‹é•¿åº¦: {len(content)}, æ¸…ç†åé•¿åº¦: {len(cleaned)}"
            )

        return cleaned

    def stop_chat(self) -> None:
        """åœæ­¢å½“å‰å¯¹è¯"""
        logger.info("æ”¶åˆ°åœæ­¢å¯¹è¯è¯·æ±‚")
        self.should_stop = True

    def _call_api_with_retry(
        self, max_retries: int = 3
    ) -> Stream[ChatCompletionChunk]:
        """
        è°ƒç”¨ APIï¼Œå¸¦é‡è¯•æœºåˆ¶

        Args:
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        Returns:
            API æµå¼å“åº”

        Raises:
            Exception: API è°ƒç”¨å¤±è´¥ä¸”é‡è¯•æ¬¡æ•°ç”¨å°½
        """
        retry_count = 0
        messages = self.message_manager.get_messages()
        tools = self._get_tools()

        logger.info(
            f"å¼€å§‹è°ƒç”¨ API (ç¬¬ {self.chat_count} è½®å¯¹è¯) - "
            f"æ¶ˆæ¯æ•°: {len(messages)}, å·¥å…·æ•°: {len(tools)}"
        )
        logger.debug(f"API è¯·æ±‚å‚æ•°: model={config.model}, temperature=0.7, top_p=0.8")

        while retry_count < max_retries:
            try:
                stream_response: Stream[ChatCompletionChunk] = (
                    self.client.chat.completions.create(
                        model=config.model,
                        messages=messages,
                        stream=True,
                        temperature=0.7,
                        top_p=0.8,
                        max_tokens=65535,
                        tools=tools,
                        tool_choice="auto",
                    )
                )
                logger.info(f"API è°ƒç”¨æˆåŠŸ (é‡è¯•æ¬¡æ•°: {retry_count})")
                return stream_response
            except Exception as e:
                retry_count += 1
                logger.error(
                    f"API è°ƒç”¨å¤±è´¥ (é‡è¯• {retry_count}/{max_retries}): {e}",
                    exc_info=True,
                )
                if retry_count >= max_retries:
                    logger.error("API è°ƒç”¨å¤±è´¥: å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                    raise

        # ç†è®ºä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œ
        raise RuntimeError("API è°ƒç”¨å¤±è´¥: å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")

    def _get_current_reasoning(self) -> str:
        """è·å–å½“å‰æ€è€ƒå†…å®¹"""
        return getattr(self, "_current_reasoning", "")

    def _set_current_reasoning(self, content: str) -> None:
        """è®¾ç½®å½“å‰æ€è€ƒå†…å®¹"""
        self._current_reasoning = content

    def _clear_current_reasoning(self) -> None:
        """æ¸…é™¤å½“å‰æ€è€ƒå†…å®¹"""
        if hasattr(self, "_current_reasoning"):
            delattr(self, "_current_reasoning")

    def _handle_reasoning_content(
        self,
        delta_content: str,
        reasoning_content: str,
        start_flag: bool,
        content: str,
        output: Callable[[str, bool], None],
        status_callback: Optional[Callable[[], None]],
    ) -> Tuple[str, bool]:
        """
        å¤„ç†æ€è€ƒå†…å®¹

        Args:
            delta_content: å¢é‡æ€è€ƒå†…å®¹
            reasoning_content: ç´¯è®¡æ€è€ƒå†…å®¹
            start_flag: æ˜¯å¦å·²å¼€å§‹è¾“å‡ºæ€è€ƒå†…å®¹
            content: å½“å‰å›å¤å†…å®¹
            output: è¾“å‡ºå›è°ƒå‡½æ•°
            status_callback: çŠ¶æ€æ›´æ–°å›è°ƒå‡½æ•°

        Returns:
            (æ›´æ–°åçš„æ€è€ƒå†…å®¹, æ˜¯å¦å·²å¼€å§‹æ ‡å¿—)
        """
        if not start_flag:
            output(
                f"\n{'='*config.log_separator_length} æ¨¡å‹æ€è€ƒ {'='*config.log_separator_length}\n"
            )
            logger.debug("å¼€å§‹æ¥æ”¶æ¨¡å‹æ€è€ƒå†…å®¹")
            start_flag = True

        reasoning_content += delta_content
        output(delta_content, end_newline=False)

        # æ›´æ–°æ€è€ƒå†…å®¹è¿½è¸ª
        current_reasoning = self._get_current_reasoning() + delta_content
        self._set_current_reasoning(current_reasoning)

        # æ›´æ–°ä¼°ç®—çš„ token
        total_completion = current_reasoning + content
        self.message_manager.update_estimated_tokens(total_completion)

        # é€šçŸ¥UIæ›´æ–°çŠ¶æ€
        if status_callback:
            status_callback()

        return reasoning_content, start_flag

    def _handle_assistant_content(
        self,
        delta_content: str,
        content: str,
        start_flag: bool,
        output: Callable[[str, bool], None],
        status_callback: Optional[Callable[[], None]],
    ) -> Tuple[str, bool]:
        """
        å¤„ç†åŠ©æ‰‹å›å¤å†…å®¹

        Args:
            delta_content: å¢é‡å›å¤å†…å®¹
            content: ç´¯è®¡å›å¤å†…å®¹
            start_flag: æ˜¯å¦å·²å¼€å§‹è¾“å‡ºå›å¤å†…å®¹
            output: è¾“å‡ºå›è°ƒå‡½æ•°
            status_callback: çŠ¶æ€æ›´æ–°å›è°ƒå‡½æ•°

        Returns:
            (æ›´æ–°åçš„å›å¤å†…å®¹, æ˜¯å¦å·²å¼€å§‹æ ‡å¿—)
        """
        if not start_flag:
            output(
                f"\n{'='*config.log_separator_length} æœ€ç»ˆå›å¤ {'='*config.log_separator_length}\n"
            )
            logger.debug("å¼€å§‹æ¥æ”¶æ¨¡å‹æœ€ç»ˆå›å¤")
            start_flag = True

        content += delta_content
        output(delta_content, end_newline=False)

        # æ›´æ–°ä¼°ç®—çš„ token
        self.message_manager.update_estimated_tokens(content)

        # é€šçŸ¥UIæ›´æ–°çŠ¶æ€
        if status_callback:
            status_callback()

        return content, start_flag

    def _handle_tool_call_delta(
        self,
        tool_call: Any,
        tool_call_acc: Dict[str, Dict[str, str]],
        last_tool_call_id: Optional[str],
        start_flag: bool,
        content: str,
        output: Callable[[str, bool], None],
        status_callback: Optional[Callable[[], None]],
    ) -> Tuple[Dict[str, Dict[str, str]], Optional[str], bool]:
        """
        å¤„ç†å·¥å…·è°ƒç”¨çš„å¢é‡æ•°æ®

        Args:
            tool_call: å·¥å…·è°ƒç”¨å¢é‡æ•°æ®
            tool_call_acc: ç´¯è®¡çš„å·¥å…·è°ƒç”¨æ•°æ®
            last_tool_call_id: ä¸Šä¸€ä¸ªå·¥å…·è°ƒç”¨ID
            start_flag: æ˜¯å¦å·²å¼€å§‹è¾“å‡ºå·¥å…·è°ƒç”¨
            content: å½“å‰å›å¤å†…å®¹
            output: è¾“å‡ºå›è°ƒå‡½æ•°
            status_callback: çŠ¶æ€æ›´æ–°å›è°ƒå‡½æ•°

        Returns:
            (æ›´æ–°åçš„å·¥å…·è°ƒç”¨ç´¯è®¡æ•°æ®, å·¥å…·è°ƒç”¨ID, æ˜¯å¦å·²å¼€å§‹æ ‡å¿—)
        """
        if not start_flag:
            output(
                f"\n{'='*config.log_separator_length} å·¥å…·è°ƒç”¨ {'='*config.log_separator_length}\n"
            )
            logger.info("å¼€å§‹æ¥æ”¶å·¥å…·è°ƒç”¨")
            start_flag = True

        tc_id = tool_call.id or last_tool_call_id
        if tc_id is None:
            logger.warning("å·¥å…·è°ƒç”¨ç¼ºå°‘ IDï¼Œè·³è¿‡")
            return tool_call_acc, last_tool_call_id, start_flag

        last_tool_call_id = tc_id

        if tc_id not in tool_call_acc:
            tool_call_acc[tc_id] = {"id": tc_id, "name": "", "arguments": ""}
            logger.debug(f"å¼€å§‹æ¥æ”¶å·¥å…·è°ƒç”¨: ID={tc_id}")

        if tool_call.function:
            if tool_call.function.name:
                tool_call_acc[tc_id]["name"] += tool_call.function.name
                output(tool_call.function.name, end_newline=False)
            if tool_call.function.arguments:
                tool_call_acc[tc_id]["arguments"] += tool_call.function.arguments
                output(tool_call.function.arguments, end_newline=False)

        # æ›´æ–°ä¼°ç®—çš„ token
        tool_call_text = ""
        for acc_tc_data in tool_call_acc.values():
            tool_call_text += acc_tc_data.get("name", "") + acc_tc_data.get(
                "arguments", ""
            )

        current_reasoning = self._get_current_reasoning()
        total_completion = current_reasoning + content + tool_call_text
        self.message_manager.update_estimated_tokens(total_completion)

        # é€šçŸ¥UIæ›´æ–°çŠ¶æ€
        if status_callback:
            status_callback()

        return tool_call_acc, last_tool_call_id, start_flag

    def _process_stream_response(
        self,
        stream_response: Stream[ChatCompletionChunk],
        output: Callable[[str, bool], None],
        status_callback: Optional[Callable[[], None]],
    ) -> Tuple[str, str, Dict[str, Dict[str, str]], Optional[Any]]:
        """
        å¤„ç†æµå¼å“åº”

        Args:
            stream_response: API æµå¼å“åº”
            output: è¾“å‡ºå›è°ƒå‡½æ•°
            status_callback: çŠ¶æ€æ›´æ–°å›è°ƒå‡½æ•°

        Returns:
            (æ€è€ƒå†…å®¹, å›å¤å†…å®¹, å·¥å…·è°ƒç”¨ç´¯è®¡æ•°æ®, usageä¿¡æ¯)
        """
        reasoning_content = "Thinking:\n"
        content = ""
        last_tool_call_id: Optional[str] = None
        tool_call_acc: Dict[str, Dict[str, str]] = {}
        usage = None

        start_reasoning_content = False
        start_content = False
        start_tool_call = False

        self._set_current_reasoning("")

        logger.debug("å¼€å§‹å¤„ç†æµå¼å“åº”")

        try:
            for chunk in stream_response:
                if self.should_stop:
                    logger.info("æµå¼å“åº”å¤„ç†è¢«ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å…³é—­æµ...")
                    stream_response.close()
                    break

                if hasattr(chunk, "usage") and chunk.usage is not None:
                    usage = chunk.usage

                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta

                    if hasattr(delta, "reasoning_content") and delta.reasoning_content:
                        reasoning_content, start_reasoning_content = (
                            self._handle_reasoning_content(
                                delta.reasoning_content,
                                reasoning_content,
                                start_reasoning_content,
                                content,
                                output,
                                status_callback,
                            )
                        )

                    if hasattr(delta, "content") and delta.content:
                        content, start_content = self._handle_assistant_content(
                            delta.content,
                            content,
                            start_content,
                            output,
                            status_callback,
                        )

                    if hasattr(delta, "tool_calls") and delta.tool_calls:
                        for tc in delta.tool_calls:
                            tool_call_acc, last_tool_call_id, start_tool_call = (
                                self._handle_tool_call_delta(
                                    tc,
                                    tool_call_acc,
                                    last_tool_call_id,
                                    start_tool_call,
                                    content,
                                    output,
                                    status_callback,
                                )
                            )

        except Exception as e:
            logger.error(f"å¤„ç†æµå¼å“åº”æ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            if not self.should_stop:
                raise
        finally:
            try:
                stream_response.close()
                logger.debug("æµå¼å“åº”å·²å…³é—­")
            except Exception:
                pass

        logger.debug(
            f"æµå¼å“åº”å¤„ç†å®Œæˆ - "
            f"æ€è€ƒé•¿åº¦: {len(reasoning_content)}, "
            f"å›å¤é•¿åº¦: {len(content)}, "
            f"å·¥å…·è°ƒç”¨æ•°: {len(tool_call_acc)}"
        )

        return reasoning_content, content, tool_call_acc, usage

    def _update_token_usage(
        self, usage: Any, status_callback: Optional[Callable[[], None]]
    ) -> None:
        """
        æ›´æ–° token ä½¿ç”¨é‡

        Args:
            usage: API è¿”å›çš„ usage ä¿¡æ¯
            status_callback: çŠ¶æ€æ›´æ–°å›è°ƒå‡½æ•°
        """
        if not usage:
            logger.warning("æµå¼å“åº”ä¸­æœªæ‰¾åˆ° usage ä¿¡æ¯")
            self._clear_current_reasoning()
            return

        prompt_tokens = getattr(usage, "prompt_tokens", None)
        if prompt_tokens is None:
            logger.warning("API å“åº”ä¸­æœªæ‰¾åˆ° prompt_tokens")
            self._clear_current_reasoning()
            return

        completion_tokens = getattr(usage, "completion_tokens", 0)
        total_tokens = getattr(usage, "total_tokens", 0)

        self.message_manager.update_token_usage(prompt_tokens)
        self._clear_current_reasoning()

        logger.info(
            f"Token ä½¿ç”¨é‡æ›´æ–° - "
            f"prompt: {prompt_tokens}, "
            f"completion: {completion_tokens}, "
            f"total: {total_tokens}, "
            f"ä½¿ç”¨ç‡: {self.message_manager.get_token_usage_percent():.2f}%"
        )

        if status_callback:
            status_callback()

    def _execute_tool_calls(
        self, tool_call_acc: Dict[str, Dict[str, str]]
    ) -> None:
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨

        Args:
            tool_call_acc: å·¥å…·è°ƒç”¨ç´¯è®¡æ•°æ®
        """
        logger.info(f"å¼€å§‹æ‰§è¡Œ {len(tool_call_acc)} ä¸ªå·¥å…·è°ƒç”¨")

        for tc_id, tc_data in tool_call_acc.items():
            tool_name = tc_data["name"]
            tool_args = tc_data["arguments"]

            logger.info(
                f"æ‰§è¡Œå·¥å…·è°ƒç”¨ - ID: {tc_id}, å·¥å…·: {tool_name}, "
                f"å‚æ•°é•¿åº¦: {len(tool_args)}"
            )
            logger.debug(f"å·¥å…·è°ƒç”¨å‚æ•°: {tool_args}")

            # æ·»åŠ åˆ°æ¶ˆæ¯å†å²
            self.message_manager.add_assistant_tool_call(tc_id, tool_name, tool_args)

            # æ‰§è¡Œå·¥å…·
            try:
                tool_call_result = self.tool_executor.execute(tool_name, tool_args)

                # å¤„ç†è¿”å›ç»“æœ
                if isinstance(tool_call_result, dict):
                    result_content = json.dumps(
                        tool_call_result, ensure_ascii=False, indent=2
                    )
                    is_success = tool_call_result.get("success", False)
                    tool_result = tool_call_result.get("result", "")
                    tool_error = tool_call_result.get("error")

                    if is_success:
                        logger.info(
                            f"å·¥å…·æ‰§è¡ŒæˆåŠŸ - ID: {tc_id}, å·¥å…·: {tool_name}, "
                            f"ç»“æœé•¿åº¦: {len(str(tool_result))}"
                        )
                    else:
                        logger.error(
                            f"å·¥å…·æ‰§è¡Œå¤±è´¥ - ID: {tc_id}, å·¥å…·: {tool_name}, "
                            f"é”™è¯¯: {tool_error}"
                        )
                else:
                    # å…¼å®¹æ—§æ ¼å¼
                    result_content = tool_call_result
                    is_success = True
                    logger.info(
                        f"å·¥å…·æ‰§è¡Œå®Œæˆ - ID: {tc_id}, å·¥å…·: {tool_name} "
                        f"(æ—§æ ¼å¼è¿”å›)"
                    )

                # æ·»åŠ åˆ°æ¶ˆæ¯å†å²
                self.message_manager.add_assistant_tool_call_result(
                    tc_id, result_content
                )

            except Exception as e:
                logger.error(
                    f"æ‰§è¡Œå·¥å…·æ—¶å‘ç”Ÿå¼‚å¸¸ - ID: {tc_id}, å·¥å…·: {tool_name}: {e}",
                    exc_info=True,
                )
                # å³ä½¿å¼‚å¸¸ä¹Ÿè¦æ·»åŠ åˆ°æ¶ˆæ¯å†å²
                error_result = json.dumps(
                    {"success": False, "result": None, "error": str(e)},
                    ensure_ascii=False,
                )
                self.message_manager.add_assistant_tool_call_result(
                    tc_id, error_result
                )

        logger.info("æ‰€æœ‰å·¥å…·è°ƒç”¨æ‰§è¡Œå®Œæˆ")

    def _handle_final_response(
        self,
        reasoning_content: str,
        content: str,
        output: Callable[[str, bool], None],
    ) -> bool:
        """
        å¤„ç†æœ€ç»ˆå›å¤

        Args:
            reasoning_content: æ€è€ƒå†…å®¹
            content: å›å¤å†…å®¹
            output: è¾“å‡ºå›è°ƒå‡½æ•°

        Returns:
            æ˜¯å¦åº”è¯¥ç»§ç»­å¾ªç¯ï¼ˆTrue=ç»§ç»­ï¼ŒFalse=ç»“æŸï¼‰
        """
        # æ£€æµ‹è™šå‡å·¥å…·è°ƒç”¨
        if self._detect_fake_tool_call_in_reasoning(reasoning_content):
            logger.warning(
                f"æ£€æµ‹åˆ°æ€è€ƒå†…å®¹ä¸­æœ‰è™šå‡çš„å·¥å…·è°ƒç”¨ - "
                f"æ€è€ƒé•¿åº¦: {len(reasoning_content)}, "
                f"å›å¤é•¿åº¦: {len(content)}"
            )

            # ä¿å­˜å†…å®¹
            if reasoning_content.strip():
                self.message_manager.add_assistant_content(reasoning_content)
            if content.strip():
                cleaned_content = self._clean_content(content)
                self.message_manager.add_assistant_content(cleaned_content)

            # æ·»åŠ æç¤ºæ¶ˆæ¯
            fake_call_message = (
                "æŠ±æ­‰ï¼Œæˆ‘åˆšåˆšåœ¨æ€è€ƒä¸­å‡è£…è°ƒç”¨äº†å·¥å…·ï¼Œç°åœ¨æˆ‘å°†ä¼šç»§ç»­å®Œæˆä»»åŠ¡ã€‚"
            )
            self.message_manager.add_assistant_content(fake_call_message)
            output(
                "\nâš ï¸ æ£€æµ‹åˆ°æ€è€ƒä¸­æœ‰å·¥å…·è°ƒç”¨æ„å›¾ï¼Œä½†æœªå®é™…è°ƒç”¨ã€‚å·²æ·»åŠ æç¤ºæ¶ˆæ¯ï¼Œç»§ç»­æ‰§è¡Œ...\n",
                end_newline=True,
            )
            logger.info("å·²æ·»åŠ è™šå‡å·¥å…·è°ƒç”¨æç¤ºæ¶ˆæ¯ï¼Œç»§ç»­æ‰§è¡Œ")
            return True  # ç»§ç»­å¾ªç¯

        # ä¿å­˜æœ€ç»ˆå›å¤
        if reasoning_content.strip():
            self.message_manager.add_assistant_content(reasoning_content)
            logger.debug(f"å·²ä¿å­˜æ€è€ƒå†…å®¹ï¼Œé•¿åº¦: {len(reasoning_content)}")

        if content.strip():
            cleaned_content = self._clean_content(content)
            self.message_manager.add_assistant_content(cleaned_content)
            logger.info(f"å·²ä¿å­˜æœ€ç»ˆå›å¤ï¼Œé•¿åº¦: {len(cleaned_content)}")

        logger.info("æœ€ç»ˆå›å¤å¤„ç†å®Œæˆï¼Œç»“æŸå¯¹è¯è½®æ¬¡")
        return False  # ç»“æŸå¾ªç¯

    def _handle_user_interruption(
        self,
        reasoning_content: str,
        content: str,
        output: Callable[[str, bool], None],
    ) -> None:
        """
        å¤„ç†ç”¨æˆ·ä¸­æ–­

        Args:
            reasoning_content: æ€è€ƒå†…å®¹
            content: å›å¤å†…å®¹
            output: è¾“å‡ºå›è°ƒå‡½æ•°
        """
        logger.info("å¤„ç†ç”¨æˆ·ä¸­æ–­è¯·æ±‚")

        # ä¿å­˜éƒ¨åˆ†å†…å®¹
        if content.strip():
            self.message_manager.add_assistant_content(reasoning_content)
            cleaned_content = self._clean_content(content)
            self.message_manager.add_assistant_content(cleaned_content)
            logger.debug("å·²ä¿å­˜ä¸­æ–­å‰çš„éƒ¨åˆ†å†…å®¹")

        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        self.message_manager.messages.append(
            {"role": "system", "content": "[ç”¨æˆ·åœ¨æ­¤å¤„ä¸­æ–­äº†å¯¹è¯ï¼Œæœªå®Œæˆçš„ä»»åŠ¡å·²æš‚åœ]"}
        )
        output("\n\n[å¯¹è¯å·²è¢«ç”¨æˆ·ä¸­æ–­]", end_newline=True)
        logger.info("å·²å°†ç”¨æˆ·ä¸­æ–­ä¿¡æ¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡")

    def chat(
        self,
        task_message: str,
        output_callback: Optional[Callable[[str, bool], None]] = None,
        status_callback: Optional[Callable[[], None]] = None,
    ) -> None:
        """
        å¤„ç†ç”¨æˆ·ä»»åŠ¡

        Args:
            task_message: ç”¨æˆ·ä»»åŠ¡æ¶ˆæ¯
            output_callback: å¯é€‰çš„è¾“å‡ºå›è°ƒå‡½æ•°ï¼Œæ¥å— (text, end_newline) å‚æ•°
                            å¦‚æœæä¾›ï¼Œå°†ä½¿ç”¨å›è°ƒè€Œä¸æ˜¯ print
            status_callback: å¯é€‰çš„çŠ¶æ€æ›´æ–°å›è°ƒå‡½æ•°ï¼Œç”¨äºå®æ—¶æ›´æ–°UIçŠ¶æ€ï¼ˆå¦‚tokenä½¿ç”¨é‡ï¼‰
        """
        logger.info(f"å¼€å§‹å¤„ç†ç”¨æˆ·ä»»åŠ¡ - æ¶ˆæ¯é•¿åº¦: {len(task_message)}")
        logger.debug(f"ç”¨æˆ·ä»»åŠ¡å†…å®¹: {task_message[:200]}...")

        # é‡ç½®ä¸­æ–­æ ‡å¿—
        self.should_stop = False

        # å®šä¹‰è¾“å‡ºå‡½æ•°
        def output(text: str, end_newline: bool = True) -> None:
            if output_callback:
                output_callback(text, end_newline)
            else:
                print(text, end="\n" if end_newline else "", flush=True)

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        self.message_manager.add_user_message(task_message)
        logger.debug("å·²æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°æ¶ˆæ¯å†å²")

        # é‡ç½®æ€è€ƒå†…å®¹è¿½è¸ª
        self._clear_current_reasoning()

        # ä¸»å¾ªç¯
        while True:
            # æ£€æŸ¥ä¸­æ–­
            if self.should_stop:
                logger.info("å¯¹è¯åœ¨ä¸»å¾ªç¯è¢«ç”¨æˆ·ä¸­æ–­")
                self.message_manager.messages.append(
                    {"role": "system", "content": "[å¯¹è¯å·²è¢«ç”¨æˆ·ä¸­æ–­]"}
                )
                output("\n\n[å¯¹è¯å·²è¢«ç”¨æˆ·ä¸­æ–­]", end_newline=True)
                break

            self.chat_count += 1
            logger.info(f"=== å¼€å§‹ç¬¬ {self.chat_count} è½®å¯¹è¯ ===")
            logger.debug(
                f"å½“å‰æ¶ˆæ¯å†å²: {json.dumps(self.message_manager.get_messages(), indent=2, ensure_ascii=False)}"
            )

            # è°ƒç”¨ API
            try:
                stream_response = self._call_api_with_retry()
            except Exception as e:
                logger.error(f"API è°ƒç”¨å¤±è´¥ï¼Œæ— æ³•ç»§ç»­: {e}", exc_info=True)
                error_msg = (
                    "\n=== é”™è¯¯ä¿¡æ¯ ===\n"
                    f"API è°ƒç”¨å¤±è´¥: {e}\n"
                    "=== é”™è¯¯ä¿¡æ¯ç»“æŸ ===\n"
                )
                output(error_msg, end_newline=True)
                return

            # å¤„ç†æµå¼å“åº”
            reasoning_content, content, tool_call_acc, usage = (
                self._process_stream_response(stream_response, output, status_callback)
            )

            # å¤„ç†ç”¨æˆ·ä¸­æ–­
            if self.should_stop:
                self._handle_user_interruption(reasoning_content, content, output)
                break

            # æ›´æ–° token ä½¿ç”¨é‡
            self._update_token_usage(usage, status_callback)

            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            if tool_call_acc:
                self._execute_tool_calls(tool_call_acc)
                logger.info("å·¥å…·è°ƒç”¨æ‰§è¡Œå®Œæˆï¼Œç»§ç»­ä¸‹ä¸€è½®å¯¹è¯")
                continue

            # å¤„ç†æœ€ç»ˆå›å¤
            should_continue = self._handle_final_response(
                reasoning_content, content, output
            )
            if not should_continue:
                break

        logger.info("ç”¨æˆ·ä»»åŠ¡å¤„ç†å®Œæˆ")
