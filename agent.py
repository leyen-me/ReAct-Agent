# -*- coding: utf-8 -*-
"""ReAct Agent ä¸»é€»è¾‘"""

import json
import logging
import re
from datetime import datetime
from typing import List, Dict, Any, Optional, Callable, Tuple

from openai import OpenAI, Stream
from openai.types.chat import ChatCompletionChunk

from config import config
from tools import (
    Tool,
    ReadFileTool,
    WriteFileTool,
    DeleteFileTool,
    CreateFileTool,
    RenameFileTool,
    ListFilesTool,
    TreeFilesTool,
    EditFileTool,
    CreateFolderTool,
    DeleteFolderTool,
    MoveFileTool,
    CopyFileTool,
    ReadCodeBlockTool,
    RunCommandTool,
    SearchInFilesTool,
    FindFilesTool,
    GitStatusTool,
    GitDiffTool,
    GitCommitTool,
    GitBranchTool,
    GitLogTool,
    UpdateStepStatusTool,
    MoveToNextStepTool,
    GetPlanStatusTool,
)
from tool_executor import create_tool_executor
from task_planner import TaskPlanner, TaskPlan, PlanStep, StepStatus

logger = logging.getLogger(__name__)


class MessageManager:
    """æ¶ˆæ¯ç®¡ç†å™¨"""

    def __init__(self, system_prompt: str, max_context_tokens: int):
        """
        åˆå§‹åŒ–æ¶ˆæ¯ç®¡ç†å™¨

        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            max_context_tokens: æœ€å¤§ä¸Šä¸‹æ–‡ token æ•°
        """
        self.max_context_tokens = max_context_tokens
        self.messages: List[Dict[str, str]] = [
            {"role": "system", "content": system_prompt}
        ]
        # å½“å‰å®é™…ä½¿ç”¨çš„ token æ•°ï¼ˆä» API å“åº”è·å–ï¼‰
        self.current_tokens: int = 0
        # ä¼°ç®—çš„ token æ•°ï¼ˆç”¨äºå®æ—¶æ˜¾ç¤ºï¼Œåœ¨æµå¼è¿‡ç¨‹ä¸­æ›´æ–°ï¼‰
        self.estimated_tokens: int = 0

    def update_token_usage(self, prompt_tokens: int) -> None:
        """
        æ›´æ–° token ä½¿ç”¨é‡ï¼ˆä» API å“åº”è·å–ï¼‰

        Args:
            prompt_tokens: API è¿”å›çš„ prompt_tokens
        """
        self.current_tokens = prompt_tokens
        self.estimated_tokens = prompt_tokens  # åŒæ­¥æ›´æ–°ä¼°ç®—å€¼
        self._manage_context()

    def estimate_tokens(self, text: str) -> int:
        """
        ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡ï¼ˆç®€å•ä¼°ç®—ï¼šä¸­æ–‡çº¦ 1.5 å­—ç¬¦/tokenï¼Œè‹±æ–‡çº¦ 4 å­—ç¬¦/tokenï¼‰

        Args:
            text: è¦ä¼°ç®—çš„æ–‡æœ¬

        Returns:
            ä¼°ç®—çš„ token æ•°
        """
        if not text:
            return 0

        # ç®€å•ä¼°ç®—ï¼šç»Ÿè®¡ä¸­æ–‡å­—ç¬¦å’Œè‹±æ–‡å­—ç¬¦
        chinese_chars = sum(1 for c in text if "\u4e00" <= c <= "\u9fff")
        other_chars = len(text) - chinese_chars

        # ä¸­æ–‡å­—ç¬¦ï¼šçº¦ 1.5 å­—ç¬¦/token
        # å…¶ä»–å­—ç¬¦ï¼ˆè‹±æ–‡ã€æ•°å­—ã€æ ‡ç‚¹ç­‰ï¼‰ï¼šçº¦ 4 å­—ç¬¦/token
        estimated = int(chinese_chars / 1.5 + other_chars / 4)
        return max(1, estimated)  # è‡³å°‘è¿”å› 1

    def update_estimated_tokens(self, completion_content: str = "") -> None:
        """
        æ›´æ–°ä¼°ç®—çš„ token ä½¿ç”¨é‡ï¼ˆç”¨äºå®æ—¶æ˜¾ç¤ºï¼‰

        Args:
            completion_content: å½“å‰å·²ç”Ÿæˆçš„ completion å†…å®¹
        """
        # ä¼°ç®— prompt tokensï¼ˆåŸºäºæ¶ˆæ¯å†å²ï¼‰
        prompt_text = ""
        for msg in self.messages:
            if msg.get("role") == "system":
                prompt_text += msg.get("content", "")
            elif msg.get("role") == "user":
                prompt_text += msg.get("content", "")
            elif msg.get("role") == "assistant":
                # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨ï¼Œä¼°ç®—å·¥å…·è°ƒç”¨çš„ token
                if "tool_calls" in msg:
                    for tc in msg.get("tool_calls", []):
                        if "function" in tc:
                            func = tc["function"]
                            prompt_text += func.get("name", "") + func.get(
                                "arguments", ""
                            )
                else:
                    # å¦‚æœæ˜¯æ™®é€šå›å¤ï¼Œä¸è®¡ç®—åˆ° prompt ä¸­ï¼ˆå› ä¸ºè¿™æ˜¯ completionï¼‰
                    pass
            elif msg.get("role") == "tool":
                prompt_text += msg.get("content", "")

        # ä¼°ç®— completion tokensï¼ˆåŸºäºå·²ç”Ÿæˆçš„å†…å®¹ï¼‰
        completion_tokens = self.estimate_tokens(completion_content)

        # æ€»ä¼°ç®— = prompt tokens + completion tokens
        # å¦‚æœå·²ç»æœ‰å®é™…çš„ current_tokensï¼ˆæ¥è‡ªä¸Šæ¬¡ API å“åº”ï¼‰ï¼Œä½¿ç”¨å®ƒä½œä¸ºåŸºç¡€
        if self.current_tokens > 0:
            # åŸºäºä¸Šæ¬¡çš„å®é™…å€¼ï¼ŒåŠ ä¸Šæ–°å¢çš„ completion tokens
            # å‡å»ä¸Šæ¬¡çš„ completion tokensï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            self.estimated_tokens = self.current_tokens + completion_tokens
        else:
            # å¦‚æœè¿˜æ²¡æœ‰å®é™…å€¼ï¼Œå®Œå…¨åŸºäºä¼°ç®—
            prompt_tokens = self.estimate_tokens(prompt_text)
            self.estimated_tokens = prompt_tokens + completion_tokens

    def get_estimated_token_usage_percent(self) -> float:
        """
        è·å–ä¼°ç®—çš„ token ä½¿ç”¨ç™¾åˆ†æ¯”ï¼ˆç”¨äºå®æ—¶æ˜¾ç¤ºï¼‰

        Returns:
            ä½¿ç”¨ç™¾åˆ†æ¯”ï¼ˆ0-100ï¼‰
        """
        return (self.estimated_tokens / self.max_context_tokens) * 100

    def get_estimated_remaining_tokens(self) -> int:
        """
        è·å–ä¼°ç®—çš„å‰©ä½™å¯ç”¨ token æ•°ï¼ˆç”¨äºå®æ—¶æ˜¾ç¤ºï¼‰

        Returns:
            å‰©ä½™ token æ•°
        """
        return max(0, self.max_context_tokens - self.estimated_tokens)

    def _manage_context(self) -> None:
        """ç®¡ç†ä¸Šä¸‹æ–‡ï¼Œå½“è¶…è¿‡é™åˆ¶æ—¶åˆ é™¤æ—§æ¶ˆæ¯ï¼ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼‰"""
        # å¦‚æœè¶…è¿‡é™åˆ¶ï¼Œåˆ é™¤æœ€æ—§çš„éç³»ç»Ÿæ¶ˆæ¯
        while self.current_tokens > self.max_context_tokens and len(self.messages) > 1:
            # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼Œåˆ é™¤ç¬¬ä¸€ä¸ªéç³»ç»Ÿæ¶ˆæ¯
            removed_message = self.messages.pop(1)
            logger.debug(
                f"ä¸Šä¸‹æ–‡å·²æ»¡ï¼Œåˆ é™¤æ—§æ¶ˆæ¯ï¼Œå½“å‰ä½¿ç”¨: {self.current_tokens}/{self.max_context_tokens}"
            )
            # æ³¨æ„ï¼šåˆ é™¤æ¶ˆæ¯åï¼Œä¸‹æ¬¡ API è°ƒç”¨æ—¶ä¼šé‡æ–°è®¡ç®— token æ•°
            # è¿™é‡Œæˆ‘ä»¬æš‚æ—¶ä¿æŒ current_tokens ä¸å˜ï¼Œç­‰å¾…ä¸‹æ¬¡ API å“åº”æ›´æ–°

    def add_user_message(self, content: str) -> None:
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯"""
        self.messages.append({"role": "user", "content": f"{content}"})

    def add_assistant_content(self, content: str) -> None:
        """æ·»åŠ åŠ©æ‰‹å†…å®¹"""
        self.messages.append({"role": "assistant", "content": f"{content}"})

    def add_assistant_tool_call_result(self, tool_call_id: str, content: str) -> None:
        """æ·»åŠ åŠ©æ‰‹å·¥å…·è°ƒç”¨ç»“æœ"""
        self.messages.append(
            {"role": "tool", "tool_call_id": tool_call_id, "content": f"{content}"}
        )

    def add_assistant_tool_call(
        self, tool_call_id: str, name: str, arguments: str = ""
    ) -> None:
        """æ·»åŠ åŠ©æ‰‹å·¥å…·è°ƒç”¨"""
        self.messages.append(
            {
                "role": "assistant",
                "tool_calls": [
                    {
                        "id": tool_call_id,
                        "type": "function",
                        "function": {
                            "name": name,
                            "arguments": arguments,
                        },
                    }
                ],
            }
        )

    def get_messages(self) -> List[Dict[str, str]]:
        """è·å–æ‰€æœ‰æ¶ˆæ¯"""
        return self.messages.copy()

    def get_token_usage_percent(self) -> float:
        """
        è·å–å½“å‰ token ä½¿ç”¨ç™¾åˆ†æ¯”

        Returns:
            ä½¿ç”¨ç™¾åˆ†æ¯”ï¼ˆ0-100ï¼‰
        """
        return (self.current_tokens / self.max_context_tokens) * 100

    def get_remaining_tokens(self) -> int:
        """
        è·å–å‰©ä½™å¯ç”¨ token æ•°

        Returns:
            å‰©ä½™ token æ•°
        """
        return max(0, self.max_context_tokens - self.current_tokens)


class ReActAgent:
    """ReAct Agent"""

    def __init__(self):
        """åˆå§‹åŒ– Agent"""
        # ç¦ç”¨ OpenAI å®¢æˆ·ç«¯çš„ HTTP æ—¥å¿—è¾“å‡º
        import httpx
        import logging

        # ç¦ç”¨ httpx çš„æ—¥å¿—
        httpx_logger = logging.getLogger("httpx")
        httpx_logger.setLevel(logging.WARNING)

        # ç¦ç”¨ httpcore çš„æ—¥å¿—ï¼ˆhttpx çš„åº•å±‚åº“ï¼‰
        httpcore_logger = logging.getLogger("httpcore")
        httpcore_logger.setLevel(logging.WARNING)

        self.client = OpenAI(
            api_key=config.api_key,
            base_url=config.base_url,
        )
        self.tools = self._create_tools()
        self.tool_executor = create_tool_executor(self.tools)
        self.message_manager = MessageManager(
            self._get_system_prompt(), config.max_context_tokens
        )
        # åˆå§‹åŒ–ä»»åŠ¡è§„åˆ’å™¨
        available_tool_names = [tool.name for tool in self.tools]
        self.task_planner = TaskPlanner(self.client, available_tool_names)
        self.current_plan: Optional[TaskPlan] = None  # å½“å‰ä»»åŠ¡è®¡åˆ’
        self.enable_planning: bool = config.enable_task_planning  # æ˜¯å¦å¯ç”¨è§„åˆ’åŠŸèƒ½
        self.chat_count = 0
        self.should_stop = False  # ä¸­æ–­æ ‡å¿—

    def _create_tools(self) -> List[Tool]:
        """åˆ›å»ºå·¥å…·åˆ—è¡¨"""

        # åˆ›å»ºä»»åŠ¡è®¡åˆ’å·¥å…·çš„å›è°ƒå‡½æ•°
        def get_plan() -> Optional[TaskPlan]:
            return self.current_plan

        tools = [
            ReadFileTool(config.work_dir),
            ReadCodeBlockTool(config.work_dir),
            WriteFileTool(config.work_dir),
            DeleteFileTool(config.work_dir),
            CreateFileTool(config.work_dir),
            RenameFileTool(config.work_dir),
            ListFilesTool(config.work_dir),
            TreeFilesTool(config.work_dir),
            CreateFolderTool(config.work_dir),
            EditFileTool(config.work_dir),
            RunCommandTool(config.work_dir, config.command_timeout),
            SearchInFilesTool(config.work_dir, config.max_search_results),
            FindFilesTool(config.work_dir, config.max_find_files),
            DeleteFolderTool(config.work_dir),
            MoveFileTool(config.work_dir),
            CopyFileTool(config.work_dir),
            GitStatusTool(config.work_dir),
            GitDiffTool(config.work_dir),
            GitCommitTool(config.work_dir),
            GitBranchTool(config.work_dir),
            GitLogTool(config.work_dir),
            # ä»»åŠ¡è®¡åˆ’ç®¡ç†å·¥å…·
            # UpdateStepStatusTool(config.work_dir, get_plan),
            # MoveToNextStepTool(config.work_dir, get_plan),
            # GetPlanStatusTool(config.work_dir, get_plan),
        ]
        return tools

    def _get_system_prompt_by_en(self) -> str:
        """Generate system prompt"""
        return f"""
You are a professional task-execution AI Agent.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Core Responsibilitiesã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Accurately understand the user's true goal, not just the surface-level question
2. Follow the execution plan if one is provided, or decompose complex tasks into executable steps
3. Complete tasks within the constraints of the current environment
4. If a task fails, analyze the cause and attempt corrective solutions
5. Stop only after confirming the task is completed

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Execution Principlesã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Prioritize execution over explanation
- If an execution plan is provided, follow it step by step
- Think through the overall plan first, then execute step by step
- Evaluate each step by whether it moves closer to the goal
- When uncertain, attempt the Minimum Viable Action (MVP)
- Do not fabricate non-existent files, commands, or results
- Report progress as you complete each step of the plan
- Keep plans concise and avoid over-decomposition (simple tasks should be 1â€“3 steps)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Task Plan Managementã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
When a task plan is provided, you are responsible for managing its execution and progress:

1. **Before starting a step**: Use the `update_step_status` tool to mark the step as "in_progress"
2. **After completing a step**: Use the `update_step_status` tool to mark the step as "completed" and provide a brief result summary
3. **If a step fails**: Use the `update_step_status` tool to mark the step as "failed" and provide error information
4. **To move to next step**: Use the `move_to_next_step` tool when you're ready to proceed to the next step
5. **To check plan status**: Use the `get_plan_status` tool to view the current plan progress and all step statuses

IMPORTANT: You must actively manage the task plan progress. Do not rely on automatic updates - you control when steps are marked as started, completed, failed, or skipped.
IMPORTANT: Do not update status for every minor action. Only update when a full plan step is actually completed.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Environment Informationã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Operating System: {config.operating_system}
Working Directory: {config.work_dir}
Current Time (Beijing Time): {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
User Language Preference: {config.user_language_preference}

You must reason and act strictly based on the above real environment.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Output Requirementsã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Output only content that is valuable to the user
- Clearly state "Task completed" after the task is finished
- If the task cannot be completed, clearly explain the reason and suggest next steps

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Prohibited Actionsã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Do not assume the existence of unspecified tools or files
- Do not claim task completion without verification
- Do not output irrelevant or verbose explanatory content
"""

    def _get_system_prompt_by_cn(self) -> str:
        """ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ï¼ˆå¾®è½¯ PM / Spec é£æ ¼ Agentï¼‰"""
        return f"""
    ä½ æ˜¯ä¸€åå¾®è½¯çš„å…¨æ ˆå¼€å‘å®ä¹ ç”Ÿï¼Œæ­£åœ¨ä½¿ç”¨ {config.operating_system}ç”µè„‘, æ­£åœ¨ä½¿ç”¨ Visual Studio Code æ‰“å¼€äº†ä¸€ä¸ªçš„æœ¬åœ°å·¥ä½œç›®å½• {config.work_dir}ã€‚å‡†å¤‡å®Œæˆ PM æä¾›çš„äº§å“éœ€æ±‚ã€‚

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€åˆå§‹çŠ¶æ€è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - å¦‚æœå°šæœªæ”¶åˆ°æ˜ç¡®ã€å¯æ‰§è¡Œçš„äº§å“éœ€æ±‚æˆ–å·¥ä½œé¡¹ï¼ˆWork Itemï¼‰ï¼š
    - æ˜ç¡®å›å¤ï¼šâ€œä½ å¥½ï¼Œæˆ‘åˆšåˆšåœ¨æ‘¸é±¼ï¼Œç°åœ¨æœ‰ä¸€äº›ç©ºé—²æ—¶é—´ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ éœ€è¦æˆ‘åšä»€ä¹ˆï¼Ÿâ€
    - ä¸è¿›è¡Œä»»åŠ¡æ‹†åˆ†
    - ä¸è°ƒç”¨ä»»ä½•å·¥å…·
    - ä¸è¾“å‡ºå¤šä½™å†…å®¹

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€å¯ç”¨å·¥å…·ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    {self._get_tools_name_and_description()}

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€æ€»ä½“ç›®æ ‡ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - å‡†ç¡®ç†è§£å½“å‰æœ‰æ•ˆçš„äº§å“éœ€æ±‚
    - åœ¨çœŸå®ç¯å¢ƒä¸çº¦æŸä¸‹å®Œæˆå®ç°
    - åœ¨éœ€æ±‚ä¸æ˜ç¡®æˆ–å­˜åœ¨é£é™©æ—¶ï¼Œä¸»åŠ¨æš´éœ²é—®é¢˜
    - ä»…è¾“å‡ºå¯¹éœ€æ±‚æ–¹ PM æœ‰ä»·å€¼çš„ç»“æœ

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€æ‰§è¡Œæµç¨‹ï¼ˆä¸¥æ ¼é˜¶æ®µåŒ–ï¼‰ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”

    ã€é˜¶æ®µ 1ï¼šéœ€æ±‚ç†è§£ã€æ¾„æ¸…ã€è¡¥å…¨é»˜è®¤å®ç°ï¼ˆUnderstandï¼‰ã€‘
    - åˆ¤æ–­å½“å‰è¾“å…¥å±äºï¼š
    - æ–°äº§å“éœ€æ±‚
    - å¯¹ç°æœ‰éœ€æ±‚çš„è¡¥å…… / ä¿®æ”¹
    - å¯¹å®ç°è¿›åº¦æˆ–ç»“æœçš„è¯¢é—®
    - åœ¨éœ€æ±‚å­˜åœ¨æ­§ä¹‰ï¼Œæ˜ç¡®æŒ‡å‡ºä¸ç¡®å®šç‚¹ï¼Œæå‡ºå¿…è¦çš„æ¾„æ¸…é—®é¢˜
    - å¯ä»¥è°ƒç”¨ä¸€äº›å¯è¯»æ€§å·¥å…·ï¼Œæ¥è¾…åŠ©ç†è§£éœ€æ±‚
    - ä½ çš„ç›®æ ‡ä¸æ˜¯â€œç­‰å¾…å®Œç¾éœ€æ±‚â€ï¼Œè€Œæ˜¯ï¼šåœ¨éœ€æ±‚ä¸å®Œæ•´æ—¶ï¼Œå…ˆåŸºäºä»£ç å’Œå¸¸è¯†ç»™å‡ºä¸€ä¸ªã€åˆç†çš„é»˜è®¤å®ç°ã€‘ï¼ŒåŒæ—¶æ˜ç¡®å“ªäº›åœ°æ–¹æ˜¯ã€ä½ çš„å·¥ç¨‹å‡è®¾ã€‘
    - å½“éœ€æ±‚è¡¨è¿°æ¨¡ç³Šæ—¶ï¼Œå…è®¸ä½ åŸºäºå·¥ç¨‹ç»éªŒè‡ªè¡Œè¡¥å…¨é»˜è®¤æ–¹æ¡ˆ

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€é˜¶æ®µ 2ï¼šä»»åŠ¡è§„åˆ’ï¼ˆPlanï¼‰ã€‘
    - åœ¨ä»¥ä¸‹æƒ…å†µè¿›å…¥è¯¥é˜¶æ®µï¼š
    - é¦–æ¬¡æ”¶åˆ°éœ€æ±‚
    - éœ€æ±‚å‘ç”Ÿå®è´¨æ€§å˜æ›´
    - å½“å‰è®¡åˆ’æ— æ³•æ»¡è¶³æœ€æ–°éœ€æ±‚

    - è¾“å‡ºå†…å®¹ï¼š
    - ç®€è¦çš„éœ€æ±‚ç†è§£æ‘˜è¦
    - åŸºäºéœ€æ±‚çš„ä»»åŠ¡æ‹†åˆ†ï¼ˆmarkdown ä»»åŠ¡åˆ—è¡¨ï¼‰
    - ä¸ºé˜²æ­¢é—å¿˜ï¼Œä½ å¯ä»¥åˆ›å»ºä¸€ä¸ª tasks ç›®å½•ï¼Œå°†ä»»åŠ¡åˆ—è¡¨ä»¥ markdown æ–‡ä»¶çš„æ ¼å¼ä¿å­˜åˆ° tasks ç›®å½•ä¸‹

    - ä»»åŠ¡æ‹†åˆ†è§„åˆ™ï¼š
    - ä»åŠŸèƒ½å±‚é¢æ‹†åˆ†ï¼Œè€Œéä»£ç ç»†èŠ‚
    - æ‹†åˆ†åˆ°â€œå•ä¸ªä»»åŠ¡å¯ä»¥åœ¨ä¸€æ¬¡å·¥å…·è°ƒç”¨æˆ–ä¸€æ¬¡æ˜ç¡®æ“ä½œä¸­å®Œæˆâ€ä¸ºæ­¢
    - ç¦æ­¢ä¸ºæ‹†åˆ†è€Œæ‹†åˆ†

    - ä»»åŠ¡çŠ¶æ€æ ‡è®°ï¼š
    - â³ å¾…æ‰§è¡Œ
    - âœ… å·²å®Œæˆ
    - ğŸŸ¡ å·²è·³è¿‡ï¼ˆå› éœ€æ±‚è°ƒæ•´ï¼‰
    - â›” å·²å¤±æ•ˆï¼ˆéœ€æ±‚è¢«æ¨ç¿»ï¼‰

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€é˜¶æ®µ 3ï¼šä»»åŠ¡æ‰§è¡Œï¼ˆExecuteï¼‰ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - ä¸¥æ ¼æŒ‰ç…§â€œâ³ å¾…æ‰§è¡Œâ€é¡ºåºæ‰§è¡Œ
    - æ¯æ¬¡åªæ‰§è¡Œä¸€ä¸ªæœ€å°ä»»åŠ¡
    - ä»…åœ¨å½“å‰ä»»åŠ¡ç¡®å®éœ€è¦æ—¶è°ƒç”¨å·¥å…·
    - å·¥å…·è°ƒç”¨å¿…é¡»æ˜ç¡®æŒ‡å®šå·¥å…·åç§°
    - ç¦æ­¢åœ¨æ€è€ƒæˆ–è§„åˆ’é˜¶æ®µè°ƒç”¨å·¥å…·

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€é˜¶æ®µ 4ï¼šéªŒè¯ä¸è¿›åº¦åŒæ­¥ï¼ˆVerify & Syncï¼‰ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - æ¯å®Œæˆä¸€ä¸ªä»»åŠ¡ï¼š
    - æ›´æ–° tasks ç›®å½•ä¸‹çš„ markdown æ–‡ä»¶ï¼Œæ ‡è®°ä»»åŠ¡çŠ¶æ€
    - åŒæ­¥å¯¹éœ€æ±‚æ–¹æœ‰ä»·å€¼çš„è¿›åº¦æˆ–ç»“æœ
    - å¦‚æœå‘ç°ï¼š
    - å®ç°ä¸éœ€æ±‚ä¸ä¸€è‡´
    - éœ€æ±‚æœ¬èº«å­˜åœ¨é—®é¢˜
    - å½“å‰æ–¹æ¡ˆå­˜åœ¨æ˜æ˜¾é£é™©
    - å¿…é¡»åŠæ—¶æŒ‡å‡ºå¹¶ç»™å‡ºå»ºè®®

    - å¦‚æœ PM åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­æå‡ºæ–°å†³ç­–ï¼š
    - ç«‹å³æš‚åœå½“å‰ä»»åŠ¡
    - å›åˆ°ã€é˜¶æ®µ 1ï¼šéœ€æ±‚ç†è§£ã€æ¾„æ¸…ã€è¡¥å…¨é»˜è®¤å®ç°ã€‘

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€é˜¶æ®µ 5ï¼šå®Œæˆæ¡ä»¶ï¼ˆDefinition of Doneï¼‰ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - ä»…åœ¨ä»¥ä¸‹æ¡ä»¶å…¨éƒ¨æ»¡è¶³æ—¶ï¼Œæ‰è®¤ä¸ºéœ€æ±‚å®Œæˆï¼š
    - å½“å‰æœ‰æ•ˆéœ€æ±‚å·²å…¨éƒ¨å®ç°
    - æ‰€æœ‰ç›¸å…³ä»»åŠ¡çŠ¶æ€ä¸ºâ€œâœ… å·²å®Œæˆâ€æˆ–â€œğŸŸ¡ å·²è·³è¿‡ï¼ˆåˆç†ï¼‰â€

    - å®Œæˆåï¼š
    - è¾“å‡ºç»“æœæ‘˜è¦
    - æ˜ç¡®è¯´æ˜ï¼šâ€œä»»åŠ¡å·²å®Œæˆâ€

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€ç¯å¢ƒçº¦æŸã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - æ“ä½œç³»ç»Ÿï¼š{config.operating_system}
    - å·¥ä½œç›®å½•ï¼š{config.work_dir}
    - å½“å‰æ—¶é—´ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
    - PM è¯­è¨€åå¥½ï¼š{config.user_language_preference}

    ä½ å¿…é¡»åŸºäºä»¥ä¸ŠçœŸå®ç¯å¢ƒè¿›è¡Œæ¨ç†ä¸è¡ŒåŠ¨ã€‚

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€è¾“å‡ºè§„èŒƒã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - åªè¾“å‡ºä¸å½“å‰é˜¶æ®µç›¸å…³çš„å†…å®¹
    - å›ç­”é—®é¢˜æ—¶ä¼˜å…ˆç»™ç»“è®ºï¼Œå…¶æ¬¡ç»™å¿…è¦ä¸Šä¸‹æ–‡
    - é¿å…æƒ…ç»ªåŒ–æˆ–éå·¥ç¨‹åŒ–è¡¨è¿°
    - ä¸è¾“å‡ºå†—ä½™è§£é‡Šæˆ–è§„åˆ™å¤è¿°

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€ç¦æ­¢äº‹é¡¹ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - ä¸è¦ç¼–é€ äº§å“éœ€æ±‚æˆ–å†³ç­–
    - ä¸è¦å¿½ç•¥æœ€æ–°çš„äº§å“å†³ç­–
    - ä¸è¦åœ¨éœ€æ±‚å·²å¤±æ•ˆæ—¶ç»§ç»­æ‰§è¡Œæ—§ä»»åŠ¡
    - ä¸è¦åœ¨æœªéªŒè¯å‰å£°ç§°â€œä»»åŠ¡å·²å®Œæˆâ€

    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€å·¥ç¨‹è´¨é‡æ£€æŸ¥ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - å‰ç«¯ä»»åŠ¡ï¼šlint / build / test
    - åç«¯ä»»åŠ¡ï¼šå•å…ƒæµ‹è¯• / é›†æˆæµ‹è¯•
    - å…¶ä»–ä»»åŠ¡ï¼šä½¿ç”¨ä¸ä»»åŠ¡ç±»å‹åŒ¹é…çš„éªŒè¯æ–¹å¼
    
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    ã€ç‰ˆæœ¬æ§åˆ¶ä¸æäº¤è§„èŒƒï¼ˆGit Disciplineï¼‰ã€‘
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    - é¡¹ç›®ä½¿ç”¨ Git è¿›è¡Œç‰ˆæœ¬æ§åˆ¶
    - æ¯å®Œæˆä¸€ä¸ªâ€œé‡è¦æ­¥éª¤ï¼ˆMilestoneï¼‰â€ï¼Œå¿…é¡»è¿›è¡Œä¸€æ¬¡æäº¤ï¼ˆcommitï¼‰

    ã€ä»€ä¹ˆæ˜¯â€œé‡è¦æ­¥éª¤â€ã€‘
    ä»¥ä¸‹ä»»æ„æƒ…å†µï¼Œè§†ä¸ºä¸€ä¸ªé‡è¦æ­¥éª¤ï¼š
    - å®Œæˆä¸€ä¸ªç‹¬ç«‹çš„åŠŸèƒ½ç‚¹
    - å®Œæˆä¸€æ¬¡å¯¹éœ€æ±‚æœ‰æ˜ç¡®ä»·å€¼çš„ä»£ç æ”¹åŠ¨
    - ä¿®å¤ä¸€ä¸ªæ˜ç¡®çš„ Bug
    - é‡æ„ä½†ä¸æ”¹å˜å¤–éƒ¨è¡Œä¸º
    - é€šè¿‡ä¸€ä¸ªå…³é”®éªŒè¯ï¼ˆbuild / test / lintï¼‰

    ã€Commit æ—¶æœºè§„åˆ™ã€‘
    - åœ¨ä»¥ä¸‹æ—¶åˆ»å¿…é¡» commitï¼š
    - å½“å‰æ­¥éª¤çš„ä»£ç å·²å¯ç‹¬ç«‹å·¥ä½œ
    - ä¸ä¾èµ–åç»­æ­¥éª¤å³å¯é€šè¿‡éªŒè¯
    - ç¦æ­¢ä»¥ä¸‹è¡Œä¸ºï¼š
    - æœªå®Œæˆçš„åŠæˆå“ commit
    - å¤šä¸ªä¸ç›¸å…³æ”¹åŠ¨æ··åœ¨ä¸€æ¬¡ commit
    - ä¸ºäº†å‡‘æ•°è€Œé¢‘ç¹ commit

    ã€Commit å‰æ£€æŸ¥ã€‘
    - ç¡®è®¤ä»£ç å¯è¿è¡Œæˆ–é€šè¿‡ç›¸åº”éªŒè¯
    - ç¡®è®¤æ”¹åŠ¨èŒƒå›´ä¸å½“å‰æ­¥éª¤ä¸€è‡´
    - ç¡®è®¤æœªå¼•å…¥ä¸å½“å‰ä»»åŠ¡æ— å…³çš„ä¿®æ”¹

    ã€Commit Message è§„èŒƒï¼ˆå¿…é¡»éµå®ˆï¼‰ã€‘
    - ä½¿ç”¨ç®€æ´ã€å·¥ç¨‹åŒ–çš„ä¸­æ–‡æè¿°
    - æ¨èæ ¼å¼ï¼š
    - feat: æ–°å¢ xxx åŠŸèƒ½
    - fix: ä¿®å¤ xxx é—®é¢˜
    - refactor: é‡æ„ xxx
    - test: æ·»åŠ /æ›´æ–° xxx æµ‹è¯•
    - chore: æ›´æ–° xxx å·¥å…·æˆ–é…ç½®

    ã€æ‰§è¡Œçº¦æŸã€‘
    - Commit åªèƒ½åœ¨ã€é˜¶æ®µ 3ï¼šä»»åŠ¡æ‰§è¡Œï¼ˆExecuteï¼‰ã€‘æˆ–ã€é˜¶æ®µ 4ï¼šéªŒè¯ä¸è¿›åº¦åŒæ­¥ï¼ˆVerify & Syncï¼‰ã€‘ä¸­è¿›è¡Œ
    - æ¯æ¬¡ commit åï¼š
    - ç®€è¦è¯´æ˜æœ¬æ¬¡æäº¤å®Œæˆäº†ä»€ä¹ˆ
    - æ›´æ–°å¯¹åº”ä»»åŠ¡çš„çŠ¶æ€
    """



    def _get_system_prompt(self) -> str:
        """ç”Ÿæˆç³»ç»Ÿæç¤ºè¯"""
        return self._get_system_prompt_by_cn()

    def _get_tools(self) -> List[Dict[str, Any]]:
        """è·å–å·¥å…·åˆ—è¡¨"""
        return [{"type": "function", "function": tool.to_dict()} for tool in self.tools]
    
    def _get_tools_name_and_description(self) -> str:
        """è·å–å·¥å…·åç§°å’Œæè¿°"""
        return "\n".join([f"- {tool.name}: {tool.description}" for tool in self.tools])
    
    def _detect_fake_tool_call_in_reasoning(self, reasoning_content: str) -> bool:
        """
        æ£€æµ‹æ€è€ƒå†…å®¹ä¸­æ˜¯å¦æœ‰è™šå‡çš„å·¥å…·è°ƒç”¨
        
        æ£€æµ‹é€»è¾‘ï¼šå¦‚æœæ€è€ƒå†…å®¹æœ«å°¾æ˜¯ JSON å¯¹è±¡ï¼Œå¾ˆå¯èƒ½æ˜¯è™šå‡çš„å·¥å…·è°ƒç”¨
        
        Args:
            reasoning_content: æ€è€ƒå†…å®¹
            
        Returns:
            æ˜¯å¦æ£€æµ‹åˆ°è™šå‡å·¥å…·è°ƒç”¨
        """
        if not reasoning_content:
            return False
        
        # å»é™¤æœ«å°¾ç©ºç™½
        content = reasoning_content.strip()
        if not content:
            return False
        
        # æŸ¥æ‰¾æœ€åä¸€ä¸ª JSON å¯¹è±¡ï¼ˆä»æœ«å°¾å¼€å§‹ï¼‰
        # æ‰¾åˆ°æœ€åä¸€ä¸ª '}' çš„ä½ç½®
        last_brace_pos = content.rfind('}')
        if last_brace_pos == -1:
            return False
        
        # ä»æœ€åä¸€ä¸ª '}' å‘å‰æŸ¥æ‰¾åŒ¹é…çš„ '{'
        brace_count = 1
        json_start = -1
        for i in range(last_brace_pos - 1, -1, -1):
            if content[i] == '}':
                brace_count += 1
            elif content[i] == '{':
                brace_count -= 1
                if brace_count == 0:
                    json_start = i
                    break
        
        # å¦‚æœæ‰¾åˆ°äº†åŒ¹é…çš„ '{'ï¼Œå°è¯•è§£æ JSON
        if json_start != -1:
            json_str = content[json_start:last_brace_pos + 1]
            # æ£€æŸ¥ JSON åé¢æ˜¯å¦åªæœ‰ç©ºç™½æˆ–æ¢è¡Œ
            after_json = content[last_brace_pos + 1:].strip()
            if not after_json or after_json in ['\n', '\r\n']:
                try:
                    parsed_json = json.loads(json_str)
                    # å¦‚æœæˆåŠŸè§£æä¸ºå­—å…¸ï¼Œè¯´æ˜æœ«å°¾æ˜¯ JSON å¯¹è±¡
                    if isinstance(parsed_json, dict):
                        return True
                except:
                    pass
        
        return False

    def stop_chat(self) -> None:
        """åœæ­¢å½“å‰å¯¹è¯"""
        self.should_stop = True

    def set_planning_enabled(self, enabled: bool) -> None:
        """è®¾ç½®æ˜¯å¦å¯ç”¨è§„åˆ’åŠŸèƒ½"""
        self.enable_planning = enabled

    def _should_create_plan(
        self,
        task_message: str,
        plan_status_callback: Optional[Callable[[str], None]] = None,
    ) -> Tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ›å»ºè®¡åˆ’ï¼ˆä½¿ç”¨ LLM æ™ºèƒ½åˆ¤æ–­ï¼‰

        Args:
            task_message: ä»»åŠ¡æ¶ˆæ¯
            plan_status_callback: å¯é€‰çš„è§„åˆ’çŠ¶æ€å›è°ƒå‡½æ•°ï¼Œç”¨äºæ›´æ–° header æ˜¾ç¤º

        Returns:
            (æ˜¯å¦éœ€è¦è§„åˆ’, åˆ¤æ–­åŸå› )
        """
        if not self.enable_planning:
            return False, "è§„åˆ’åŠŸèƒ½å·²ç¦ç”¨"

        # å¦‚æœå·²ç»æœ‰è®¡åˆ’åœ¨æ‰§è¡Œï¼Œä¸åˆ›å»ºæ–°è®¡åˆ’
        if self.current_plan and self.current_plan.get_progress()["completed"] < len(
            self.current_plan.steps
        ):
            return False, "å·²æœ‰è®¡åˆ’æ­£åœ¨æ‰§è¡Œä¸­"

        # æ¸…ç†æ¶ˆæ¯ï¼Œå»é™¤é¦–å°¾ç©ºç™½
        message = task_message.strip()

        # ç©ºæ¶ˆæ¯ä¸éœ€è¦è§„åˆ’
        if not message:
            return False, "æ¶ˆæ¯ä¸ºç©º"

        # ä½¿ç”¨ LLM æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦è§„åˆ’ï¼ˆå®Œå…¨äº¤ç»™æ¨¡å‹åˆ¤æ–­ï¼Œä¸é¢„è®¾è§„åˆ™ï¼‰
        try:
            if plan_status_callback:
                plan_status_callback("ğŸ” åˆ¤æ–­æ˜¯å¦éœ€è¦è§„åˆ’...")

            # æ„å»ºæ ‡å‡†çš„åˆ¤æ–­æç¤ºè¯ï¼ˆå‚è€ƒ OpenAI/Anthropic æœ€ä½³å®è·µï¼‰
            system_prompt = """You are a task analysis assistant. Your role is to determine whether a user's request requires detailed task planning before execution.

Task planning is needed when:
- The request requires using tools (file operations, command execution, Git operations, etc.)
- The request involves multiple steps or complex workflows
- The request needs to be broken down into smaller actionable steps

Task planning is NOT needed when:
- The request is a simple greeting or expression of gratitude
- The request is a straightforward knowledge question that can be answered directly
- The request is a simple informational query
- The request can reasonably be completed in 1â€“3 actions, even if it uses tools

Respond with only "yes" or "no" followed by a brief reason in parentheses."""

            user_prompt = f"""Analyze the following user request and determine if it requires detailed task planning:

User request: "{message}"

Respond with: "yes (reason)" or "no (reason)"."""

            # ä½¿ç”¨æµå¼è¾“å‡ºï¼ˆä½¿ç”¨è§„åˆ’æ¨¡å‹ï¼‰
            stream_response = self.client.chat.completions.create(
                model=config.planning_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0.1,  # Very low temperature for deterministic classification
                stream=True,
                extra_body={"thinking": {"type": "disabled"}},
            )

            result = ""
            try:
                for chunk in stream_response:
                    if chunk.choices and len(chunk.choices) > 0:
                        delta = chunk.choices[0].delta
                        if hasattr(delta, "content") and delta.content:
                            result += delta.content
                            if plan_status_callback:
                                plan_status_callback(f"ğŸ” åˆ¤æ–­ä¸­: {result[:30]}...")
            finally:
                try:
                    stream_response.close()
                except:
                    pass

            result = result.strip()
            result_lower = result.lower()

            # è§£æç»“æœï¼šæå– yes/no å’ŒåŸå› 
            needs_planning = any(
                result_lower.startswith(prefix) for prefix in ["yes", "y"]
            )

            # æå–åŸå› ï¼ˆå¦‚æœæœ‰ï¼‰
            reason = "LLMåˆ¤æ–­"
            if "(" in result and ")" in result:
                try:
                    reason = result.split("(")[1].split(")")[0].strip()
                except:
                    pass

            logger.debug(
                f"è§„åˆ’åˆ¤æ–­: '{message}' -> {needs_planning} (åŸå› : {reason}, LLMå›ç­”: {result})"
            )
            return needs_planning, reason

        except Exception as e:
            logger.warning(f"è§„åˆ’åˆ¤æ–­å¤±è´¥: {e}ï¼Œé»˜è®¤ä¸è§„åˆ’")
            if plan_status_callback:
                plan_status_callback(f"âš ï¸ åˆ¤æ–­å¤±è´¥")
            return False, f"åˆ¤æ–­å¤±è´¥: {str(e)}"

    def chat(
        self,
        task_message: str,
        output_callback: Optional[Callable[[str, bool], None]] = None,
        plan_status_callback: Optional[Callable[[str], None]] = None,
        status_callback: Optional[Callable[[], None]] = None,
    ) -> None:
        """
        å¤„ç†ç”¨æˆ·ä»»åŠ¡

        Args:
            task_message: ç”¨æˆ·ä»»åŠ¡æ¶ˆæ¯
            output_callback: å¯é€‰çš„è¾“å‡ºå›è°ƒå‡½æ•°ï¼Œæ¥å— (text, end_newline) å‚æ•°
                            å¦‚æœæä¾›ï¼Œå°†ä½¿ç”¨å›è°ƒè€Œä¸æ˜¯ print
            plan_status_callback: å¯é€‰çš„è§„åˆ’çŠ¶æ€å›è°ƒå‡½æ•°ï¼Œæ¥å— (status_text) å‚æ•°
                                 ç”¨äºæ›´æ–° header ä¸­çš„è§„åˆ’çŠ¶æ€æ˜¾ç¤º
            status_callback: å¯é€‰çš„çŠ¶æ€æ›´æ–°å›è°ƒå‡½æ•°ï¼Œç”¨äºå®æ—¶æ›´æ–°UIçŠ¶æ€ï¼ˆå¦‚tokenä½¿ç”¨é‡ï¼‰
        """
        # é‡ç½®ä¸­æ–­æ ‡å¿—
        self.should_stop = False

        # å®šä¹‰è¾“å‡ºå‡½æ•°
        def output(text: str, end_newline: bool = True):
            if output_callback:
                output_callback(text, end_newline)
            else:
                print(text, end="\n" if end_newline else "", flush=True)

        # å®šä¹‰è§„åˆ’çŠ¶æ€æ›´æ–°å‡½æ•°
        def update_plan_status(status: str):
            if plan_status_callback:
                plan_status_callback(status)

        # ä»»åŠ¡è§„åˆ’é˜¶æ®µ - æ˜¾ç¤ºåˆ¤æ–­ç»“æœ
        needs_planning, _reason = self._should_create_plan(
            task_message, update_plan_status
        )

        if needs_planning:
            update_plan_status("ğŸ“‹ åˆ†æä»»åŠ¡ä¸­...")

            try:
                self.current_plan = self.task_planner.create_plan(
                    task_message, update_plan_status
                )

                # æ›´æ–°è§„åˆ’çŠ¶æ€ä¸ºè¿›åº¦æ˜¾ç¤º
                progress = self.current_plan.get_progress()
                update_plan_status(
                    f"ğŸ“‹ è®¡åˆ’å®Œæˆ ({len(self.current_plan.steps)} æ­¥) | è¿›åº¦: {progress['completed']}/{progress['total']}"
                )

                # å°†å®Œæ•´çš„è®¡åˆ’ä¿¡æ¯æ·»åŠ åˆ°æ¶ˆæ¯ä¸­ï¼Œè®©æ¨¡å‹çŸ¥é“è®¡åˆ’å¹¶å¯ä»¥ç®¡ç†å®ƒ
                plan_info = f"\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                plan_info += (
                    f"ğŸ“‹ ä»»åŠ¡æ‰§è¡Œè®¡åˆ’ï¼ˆå…± {len(self.current_plan.steps)} æ­¥ï¼‰\n"
                )
                plan_info += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                plan_info += f"ä»»åŠ¡æè¿°ï¼š{self.current_plan.task_description}\n\n"
                plan_info += f"å½“å‰è¿›åº¦ï¼š{progress['completed']}/{progress['total']} å·²å®Œæˆ ({progress['progress_percent']:.1f}%)\n"
                plan_info += f"å¾…æ‰§è¡Œï¼š{progress['pending']} | æ‰§è¡Œä¸­ï¼š{progress['in_progress']} | å¤±è´¥ï¼š{progress['failed']}\n\n"
                plan_info += f"æ‰§è¡Œæ­¥éª¤ï¼š\n"
                for step in self.current_plan.steps:
                    status_icon = {
                        StepStatus.PENDING: "â³",
                        StepStatus.IN_PROGRESS: "ğŸ”„",
                        StepStatus.COMPLETED: "âœ…",
                        StepStatus.FAILED: "âŒ",
                        StepStatus.SKIPPED: "â­ï¸",
                    }.get(step.status, "â“")
                    plan_info += (
                        f"{status_icon} æ­¥éª¤ {step.step_number}: {step.description}"
                    )
                    if step.expected_tools:
                        plan_info += f" [é¢„æœŸå·¥å…·: {', '.join(step.expected_tools)}]"
                    plan_info += f"\n"
                    if step.status == StepStatus.COMPLETED and step.result:
                        plan_info += f"   âœ“ ç»“æœ: {step.result[:100]}{'...' if len(step.result) > 100 else ''}\n"
                    elif step.status == StepStatus.FAILED and step.error:
                        plan_info += f"   âœ— é”™è¯¯: {step.error}\n"
                plan_info += f"\né‡è¦æç¤ºï¼šä½ éœ€è¦ä½¿ç”¨ä»»åŠ¡è®¡åˆ’ç®¡ç†å·¥å…·ï¼ˆupdate_step_status, move_to_next_step, get_plan_statusï¼‰æ¥ä¸»åŠ¨ç®¡ç†è®¡åˆ’çš„æ‰§è¡Œè¿›åº¦ã€‚\n"
                plan_info += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                task_message = f"{task_message}{plan_info}"

            except Exception as e:
                logger.error(f"è§„åˆ’å¤±è´¥: {e}")
                update_plan_status(f"âš ï¸ è§„åˆ’å¤±è´¥: {str(e)[:30]}")
                self.current_plan = None
        else:
            logger.debug(f"ç›´æ¥æ‰§è¡Œä»»åŠ¡: {task_message}")
            # æ¸…é™¤è§„åˆ’çŠ¶æ€
            update_plan_status("")

        self.message_manager.add_user_message(task_message)
        # é‡ç½® reasoning content è¿½è¸ªï¼ˆæ¯æ¬¡æ–°çš„å¯¹è¯è½®æ¬¡ï¼‰
        if hasattr(self, "_current_reasoning"):
            delattr(self, "_current_reasoning")
        while True:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸­æ–­ï¼ˆåœ¨ä¸»å¾ªç¯å¼€å§‹æ—¶ï¼‰
            if self.should_stop:
                logger.info("å¯¹è¯åœ¨ä¸»å¾ªç¯è¢«ç”¨æˆ·ä¸­æ–­")
                # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯è¯´æ˜ç”¨æˆ·ä¸­æ–­äº†å¯¹è¯
                self.message_manager.messages.append(
                    {"role": "system", "content": "[å¯¹è¯å·²è¢«ç”¨æˆ·ä¸­æ–­]"}
                )
                output("\n\n[å¯¹è¯å·²è¢«ç”¨æˆ·ä¸­æ–­]", end_newline=True)
                break
            self.chat_count += 1

            # å¦‚æœæœ‰ä»»åŠ¡è®¡åˆ’ï¼Œåœ¨æ¯æ¬¡å¾ªç¯å¼€å§‹æ—¶å°†å½“å‰è®¡åˆ’çŠ¶æ€ä¼ é€’ç»™å¤§æ¨¡å‹
            if self.current_plan:
                progress = self.current_plan.get_progress()
                current_step = self.current_plan.get_current_step()
                plan_status_info = f"\n[ä»»åŠ¡è®¡åˆ’çŠ¶æ€æ›´æ–°]\n"
                plan_status_info += f"è¿›åº¦: {progress['completed']}/{progress['total']} å·²å®Œæˆ ({progress['progress_percent']:.1f}%)\n"
                plan_status_info += f"å¾…æ‰§è¡Œ: {progress['pending']} | æ‰§è¡Œä¸­: {progress['in_progress']} | å¤±è´¥: {progress['failed']}\n"
                if current_step:
                    plan_status_info += f"å½“å‰æ­¥éª¤: {current_step.step_number} - {current_step.description} (çŠ¶æ€: {current_step.status.value})\n"
                plan_status_info += f"æç¤º: ä½¿ç”¨ä»»åŠ¡è®¡åˆ’ç®¡ç†å·¥å…·ï¼ˆupdate_step_status, move_to_next_step, get_plan_statusï¼‰æ¥ç®¡ç†è®¡åˆ’è¿›åº¦ã€‚\n"
                # å°†è®¡åˆ’çŠ¶æ€ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­ï¼ˆåªåœ¨å½“å‰å¾ªç¯ä¸­ä½¿ç”¨ï¼‰
                # æ³¨æ„ï¼šè¿™é‡Œä¸ç›´æ¥ä¿®æ”¹message_manager.messagesï¼Œè€Œæ˜¯åœ¨APIè°ƒç”¨æ—¶ä¸´æ—¶æ·»åŠ 
                messages_with_plan = self.message_manager.get_messages() + [
                    {"role": "system", "content": plan_status_info}
                ]
            else:
                messages_with_plan = self.message_manager.get_messages()

            logger.debug(f"=== Chat Round {self.chat_count} ===")
            logger.debug(
                f"Messages: {json.dumps(messages_with_plan, indent=2, ensure_ascii=False)}"
            )

            # è°ƒç”¨ APIï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            max_retries = 3
            retry_count = 0

            while retry_count < max_retries:
                try:
                    stream_response: Stream[ChatCompletionChunk] = (
                        self.client.chat.completions.create(
                            model=config.execution_model,  # ä½¿ç”¨æ‰§è¡Œæ¨¡å‹
                            messages=messages_with_plan,  # ä½¿ç”¨åŒ…å«è®¡åˆ’çŠ¶æ€çš„æ¶ˆæ¯
                            stream=True,
                            temperature=0.7,
                            top_p=0.8,
                            max_tokens=65535,
                            tools=self._get_tools(),
                            tool_choice="auto",
                            extra_body={"thinking": {"type": "disabled"}},
                        )
                    )
                    break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                except Exception as e:
                    retry_count += 1
                    logger.error(f"API è°ƒç”¨å¤±è´¥: {e}")
                    raise

            else:
                # é‡è¯•æ¬¡æ•°ç”¨å°½
                logger.error("API è°ƒç”¨å¤±è´¥: å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                error_msg = "\n=== é”™è¯¯ä¿¡æ¯ ===\nAPI è°ƒç”¨å¤±è´¥: å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°\n=== é”™è¯¯ä¿¡æ¯ç»“æŸ ===\n"
                output(error_msg, end_newline=True)
                return  # ä¼˜é›…é€€å‡ºï¼Œä¸æŠ›å‡ºå¼‚å¸¸

            # å¤„ç†æµå¼å“åº”
            reasoning_content = "Thinking:\n"
            content = ""
            last_tool_call_id = None
            tool_call_acc = {}
            usage = None

            start_reasoning_content = False
            start_content = False
            start_tool_call = False

            # åˆå§‹åŒ– reasoning content è¿½è¸ª
            self._current_reasoning = ""

            # å®šä¹‰è¾“å‡ºå‡½æ•°ï¼ˆå·²åœ¨æ–¹æ³•å¼€å§‹å¤„å®šä¹‰ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤å®šä¹‰ï¼‰

            try:
                for chunk in stream_response:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸­æ–­
                    if self.should_stop:
                        logger.info("æµå¼å“åº”è¢«ä¸­æ–­ï¼Œæ­£åœ¨å…³é—­æµ...")
                        stream_response.close()  # å…³é—­æµï¼Œåœæ­¢åç«¯ç»§ç»­ç”Ÿæˆ
                        break

                    # è·å– usage ä¿¡æ¯ï¼ˆé€šå¸¸åœ¨æœ€åä¸€ä¸ª chunk ä¸­ï¼‰
                    if hasattr(chunk, "usage") and chunk.usage is not None:
                        usage = chunk.usage

                    if chunk.choices and len(chunk.choices) > 0:
                        delta = chunk.choices[0].delta

                        if (
                            hasattr(delta, "reasoning_content")
                            and delta.reasoning_content
                        ):
                            if not start_reasoning_content:
                                output(
                                    f"\n{'='*config.log_separator_length} æ¨¡å‹æ€è€ƒ {'='*config.log_separator_length}\n"
                                )
                                start_reasoning_content = True
                            _reasoning_content = delta.reasoning_content
                            reasoning_content += delta.reasoning_content
                            output(_reasoning_content, end_newline=False)
                            # å®æ—¶æ›´æ–°ä¼°ç®—çš„ tokenï¼ˆreasoning content ä¹Ÿä¼šæ¶ˆè€— tokensï¼‰
                            # è¿™é‡Œæˆ‘ä»¬ç®€å•åœ°å°† reasoning content ä¹Ÿè®¡å…¥ completion
                            # æ³¨æ„ï¼šreasoning å’Œ content æ˜¯åˆ†å¼€çš„ï¼Œä½†éƒ½è®¡å…¥ completion tokens
                            if not hasattr(self, "_current_reasoning"):
                                self._current_reasoning = ""
                            self._current_reasoning += _reasoning_content
                            # ä¼°ç®—æ—¶è€ƒè™‘ reasoning å’Œ content
                            total_completion = (
                                self._current_reasoning
                                if hasattr(self, "_current_reasoning")
                                else ""
                            ) + content
                            self.message_manager.update_estimated_tokens(
                                total_completion
                            )
                            # é€šçŸ¥UIæ›´æ–°çŠ¶æ€ï¼ˆå®æ—¶æ›´æ–°tokenæ˜¾ç¤ºï¼‰
                            if status_callback:
                                status_callback()

                        if hasattr(delta, "content") and delta.content:
                            if not start_content:
                                output(
                                    f"\n{'='*config.log_separator_length} æœ€ç»ˆå›å¤ {'='*config.log_separator_length}\n"
                                )
                                start_content = True
                            chunk_content = delta.content
                            content += chunk_content
                            output(chunk_content, end_newline=False)
                            # å®æ—¶æ›´æ–°ä¼°ç®—çš„ tokenï¼ˆåŸºäºå·²ç”Ÿæˆçš„å†…å®¹ï¼‰
                            self.message_manager.update_estimated_tokens(content)
                            # é€šçŸ¥UIæ›´æ–°çŠ¶æ€ï¼ˆå®æ—¶æ›´æ–°tokenæ˜¾ç¤ºï¼‰
                            if status_callback:
                                status_callback()

                        if hasattr(delta, "tool_calls") and delta.tool_calls:
                            if not start_tool_call:
                                output(
                                    f"\n{'='*config.log_separator_length} å·¥å…·è°ƒç”¨ {'='*config.log_separator_length}\n"
                                )
                                start_tool_call = True
                            for tc in delta.tool_calls:
                                tc_id = tc.id or last_tool_call_id

                                if tc_id is None:
                                    # è¿ç¬¬ä¸€ä¸ª id éƒ½æ²¡æœ‰ï¼Œç›´æ¥è·³è¿‡ï¼ˆæå°‘è§ï¼‰
                                    continue

                                last_tool_call_id = tc_id

                                if tc_id not in tool_call_acc:
                                    tool_call_acc[tc_id] = {
                                        "id": tc_id,
                                        "name": "",
                                        "arguments": "",
                                    }

                                # æ‹¼ nameï¼ˆè™½ç„¶ä¸€èˆ¬åªæ¥ä¸€æ¬¡ï¼Œä½†è§„èŒƒå…è®¸æ‹†ï¼‰
                                if tc.function:
                                    if tc.function.name:
                                        tool_call_acc[tc_id]["name"] += tc.function.name
                                        output(tc.function.name, end_newline=False)
                                    if tc.function.arguments:
                                        tool_call_acc[tc_id][
                                            "arguments"
                                        ] += tc.function.arguments
                                        output(tc.function.arguments, end_newline=False)

                                    # å®æ—¶æ›´æ–°ä¼°ç®—çš„ tokenï¼ˆå·¥å…·è°ƒç”¨ä¹Ÿä¼šæ¶ˆè€— tokensï¼‰
                                    # æ„å»ºå·¥å…·è°ƒç”¨çš„å®Œæ•´æ–‡æœ¬ç”¨äºä¼°ç®—
                                    tool_call_text = ""
                                    for acc_tc_id, acc_tc_data in tool_call_acc.items():
                                        tool_call_text += acc_tc_data.get(
                                            "name", ""
                                        ) + acc_tc_data.get("arguments", "")
                                    # ä¼°ç®—æ—¶è€ƒè™‘ reasoningã€content å’Œ tool_calls
                                    total_completion = (
                                        (
                                            self._current_reasoning
                                            if hasattr(self, "_current_reasoning")
                                            else ""
                                        )
                                        + content
                                        + tool_call_text
                                    )
                                    self.message_manager.update_estimated_tokens(
                                        total_completion
                                    )
                                    # é€šçŸ¥UIæ›´æ–°çŠ¶æ€ï¼ˆå®æ—¶æ›´æ–°tokenæ˜¾ç¤ºï¼‰
                                    if status_callback:
                                        status_callback()
            except Exception as e:
                # å¦‚æœåœ¨å¤„ç†æµæ—¶å‘ç”Ÿå¼‚å¸¸ï¼ˆåŒ…æ‹¬å…³é—­æµï¼‰ï¼Œè®°å½•æ—¥å¿—
                logger.debug(f"æµå¤„ç†å¼‚å¸¸: {e}")
                # å¦‚æœæ˜¯ç”¨æˆ·ä¸­æ–­ï¼Œä¸éœ€è¦æŠ›å‡ºå¼‚å¸¸
                if not self.should_stop:
                    raise
            finally:
                # ç¡®ä¿æµè¢«å…³é—­
                try:
                    stream_response.close()
                except Exception:
                    pass

            # å¦‚æœç”¨æˆ·ä¸­æ–­äº†å¯¹è¯ï¼Œå°†ä¸­æ–­ä¿¡æ¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
            if self.should_stop:
                # å¦‚æœæœ‰éƒ¨åˆ†å†…å®¹ï¼Œå…ˆä¿å­˜
                if content.strip():
                    self.message_manager.add_assistant_content(reasoning_content)
                    self.message_manager.add_assistant_content(content)
                # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯è¯´æ˜ç”¨æˆ·ä¸­æ–­äº†å¯¹è¯
                self.message_manager.messages.append(
                    {
                        "role": "system",
                        "content": "[ç”¨æˆ·åœ¨æ­¤å¤„ä¸­æ–­äº†å¯¹è¯ï¼Œæœªå®Œæˆçš„ä»»åŠ¡å·²æš‚åœ]",
                    }
                )
                logger.info("å·²å°†ç”¨æˆ·ä¸­æ–­ä¿¡æ¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡")
                break

            # æ›´æ–° token ä½¿ç”¨é‡ï¼ˆä» API å“åº”è·å–ï¼‰
            if usage:
                prompt_tokens = getattr(usage, "prompt_tokens", None)
                if prompt_tokens is not None:
                    self.message_manager.update_token_usage(prompt_tokens)
                    completion_tokens = getattr(usage, "completion_tokens", 0)
                    total_tokens = getattr(usage, "total_tokens", 0)
                    logger.debug(
                        f"\nToken ä½¿ç”¨: prompt={prompt_tokens}, completion={completion_tokens}, total={total_tokens}"
                    )
                    # æ¸…é™¤ä¸´æ—¶å˜é‡
                    if hasattr(self, "_current_reasoning"):
                        delattr(self, "_current_reasoning")
                    # é€šçŸ¥UIæ›´æ–°çŠ¶æ€ï¼ˆæ›´æ–°ä¸ºå®é™…å€¼ï¼‰
                    if status_callback:
                        status_callback()
                else:
                    logger.warning("\nAPI å“åº”ä¸­æœªæ‰¾åˆ° prompt_tokens")
            else:
                logger.warning("\næµå¼å“åº”ä¸­æœªæ‰¾åˆ° usage ä¿¡æ¯")
                # å³ä½¿æ²¡æœ‰ usageï¼Œä¹Ÿæ¸…é™¤ä¸´æ—¶å˜é‡
                if hasattr(self, "_current_reasoning"):
                    delattr(self, "_current_reasoning")

            if tool_call_acc:
                # å¦‚æœæœ‰ä»»åŠ¡è®¡åˆ’ï¼Œæ›´æ–°UIæ˜¾ç¤ºï¼ˆä½†ä¸è‡ªåŠ¨æ›´æ–°è®¡åˆ’çŠ¶æ€ï¼Œç”±å¤§æ¨¡å‹è‡ªå·±ç®¡ç†ï¼‰
                if self.current_plan:
                    progress = self.current_plan.get_progress()
                    current_step = self.current_plan.get_current_step()
                    if current_step:
                        update_plan_status(
                            f"ğŸ“‹ æ‰§è¡Œä¸­: {progress['completed']}/{progress['total']} ({progress['progress_percent']:.0f}%) | æ­¥éª¤ {current_step.step_number}"
                        )
                    else:
                        update_plan_status(
                            f"ğŸ“‹ æ‰§è¡Œä¸­: {progress['completed']}/{progress['total']} ({progress['progress_percent']:.0f}%)"
                        )

                for tc_id, tc_data in tool_call_acc.items():
                    # logger.info(f"=== Tool Call ===")
                    # logger.debug(f"name: {tc_data['name']}")
                    # logger.debug(f"arguments: {tc_data['arguments']}")
                    self.message_manager.add_assistant_tool_call(
                        tc_id, tc_data["name"], tc_data["arguments"]
                    )
                    tool_call_result = self.tool_executor.execute(
                        tc_data["name"], tc_data["arguments"]
                    )
                    result_content = None
                    # å¤„ç†æ ‡å‡†åŒ–çš„è¿”å›æ ¼å¼
                    if isinstance(tool_call_result, dict):
                        result_content = json.dumps(
                            tool_call_result, ensure_ascii=False, indent=2
                        )
                        # æ£€æŸ¥å·¥å…·æ‰§è¡Œæ˜¯å¦æˆåŠŸ
                        is_success = tool_call_result.get("success", False)
                        tool_result = tool_call_result.get("result", "")
                        tool_error = tool_call_result.get("error")
                    else:
                        # å…¼å®¹æ—§çš„è¿”å›æ ¼å¼
                        result_content = tool_call_result
                        is_success = True  # å‡è®¾æˆåŠŸ
                        tool_result = tool_call_result
                        tool_error = None

                    # æ£€æŸ¥æ˜¯å¦æ˜¯ä»»åŠ¡è®¡åˆ’ç®¡ç†å·¥å…·ï¼Œå¦‚æœæ˜¯åˆ™æ›´æ–°UIæ˜¾ç¤º
                    if self.current_plan and tc_data["name"] in [
                        "update_step_status",
                        "move_to_next_step",
                        "get_plan_status",
                    ]:
                        # è§£æå·¥å…·ç»“æœä»¥æ›´æ–°UI
                        try:
                            if isinstance(
                                tool_call_result, dict
                            ) and tool_call_result.get("success"):
                                progress = self.current_plan.get_progress()
                                current_step = self.current_plan.get_current_step()
                                if current_step:
                                    update_plan_status(
                                        f"ğŸ“‹ æ‰§è¡Œä¸­: {progress['completed']}/{progress['total']} ({progress['progress_percent']:.0f}%) | æ­¥éª¤ {current_step.step_number}"
                                    )
                                else:
                                    update_plan_status(
                                        f"ğŸ“‹ æ‰§è¡Œä¸­: {progress['completed']}/{progress['total']} ({progress['progress_percent']:.0f}%)"
                                    )
                        except:
                            pass

                    self.message_manager.add_assistant_tool_call_result(
                        tc_data["id"], result_content
                    )

                continue
            else:
                # æœ€ç»ˆå›å¤é˜¶æ®µ
                # æ£€æµ‹æ˜¯å¦æœ‰è™šå‡çš„å·¥å…·è°ƒç”¨ï¼ˆåœ¨æ€è€ƒä¸­å‡è£…è°ƒç”¨å·¥å…·ï¼‰
                if self._detect_fake_tool_call_in_reasoning(reasoning_content):
                    logger.warning("æ£€æµ‹åˆ°æ€è€ƒå†…å®¹ä¸­æœ‰è™šå‡çš„å·¥å…·è°ƒç”¨ï¼Œä½†æœªå®é™…è°ƒç”¨å·¥å…·")
                    # ä¿å­˜å½“å‰çš„æ€è€ƒå†…å®¹å’Œå›å¤å†…å®¹
                    if reasoning_content.strip():
                        self.message_manager.add_assistant_content(reasoning_content)
                    if content.strip():
                        self.message_manager.add_assistant_content(content)
                    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼Œæç¤ºç»§ç»­æ‰§è¡Œ
                    fake_call_message = "sorry, I'm not able to call the tool right now, please try again later..."
                    self.message_manager.add_user_message(fake_call_message)
                    output(f"\nâš ï¸ æ£€æµ‹åˆ°æ€è€ƒä¸­æœ‰å·¥å…·è°ƒç”¨æ„å›¾ï¼Œä½†æœªå®é™…è°ƒç”¨ã€‚å·²æ·»åŠ æç¤ºæ¶ˆæ¯ï¼Œç»§ç»­æ‰§è¡Œ...\n", end_newline=True)
                    # ç»§ç»­å¾ªç¯
                    continue
                
                # logger.info(f"=== Final Answer ===")
                # logger.info(content)

                # å¦‚æœæœ‰ä»»åŠ¡è®¡åˆ’ï¼Œæ›´æ–°UIæ˜¾ç¤ºæœ€ç»ˆè¿›åº¦ï¼ˆä½†ä¸è‡ªåŠ¨æ›´æ–°è®¡åˆ’çŠ¶æ€ï¼‰
                if self.current_plan:
                    final_progress = self.current_plan.get_progress()
                    if final_progress["total"] > 0:
                        # æ›´æ–° header ä¸­çš„è§„åˆ’çŠ¶æ€
                        status_text = f"âœ… å®Œæˆ: {final_progress['completed']}/{final_progress['total']} ({final_progress['progress_percent']:.0f}%)"
                        if final_progress["failed"] > 0:
                            status_text += f" âš ï¸{final_progress['failed']}"
                        update_plan_status(status_text)

                if reasoning_content.strip():
                    self.message_manager.add_assistant_content(reasoning_content)
                if content.strip():
                    self.message_manager.add_assistant_content(content)
                break
